{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788da39c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95539adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from helpers.helper_functions import *\n",
    "from helpers.helper_classes import *\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "import timeit\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95be1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data\n",
    "df_train = pd.read_parquet('../data/training_set.parquet', engine = 'auto')\n",
    "#df_train = df_train[df_train['srch_id'] < 10000]\n",
    "df_test = pd.read_parquet('../data/test_set.parquet', engine = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581da370",
   "metadata": {},
   "source": [
    "<h1>Data prep<h1\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671eca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score(df):\n",
    "    df.loc[:, 'score'] = np.zeros(len(df))\n",
    "    df.loc[df['click_bool'] == 1, 'score'] = 1\n",
    "    df.loc[df['booking_bool'] == 1, 'score'] = 5\n",
    "    return df\n",
    "\n",
    "# Add features for hour, day and month.\n",
    "def date_time(df):\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    df['day'] = df['date_time'].dt.day\n",
    "    df['month'] = df['date_time'].dt.month\n",
    "    df = df.drop('date_time', axis=1)\n",
    "    return df\n",
    "\n",
    "def remove_cols(df, cols):\n",
    "    return df.drop(cols, axis=1)\n",
    "\n",
    "def remove_cols_nan(df, limit):\n",
    "    for col in df.columns:\n",
    "        if len(df[col]) * limit < df[col].isna().sum():\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df\n",
    "\n",
    "# Add column with a ranking for each property in a search based on another column.\n",
    "def create_rank_feature(df, col):\n",
    "    df['rank_' + str(col)] = df.groupby('srch_id')[col].rank(ascending=False)\n",
    "    return df\n",
    "\n",
    "# location score 2 has missing values for property on some rows while some rows have a score.\n",
    "# take average of rows that do have a score. reduces nans from 1090348 to 182213.\n",
    "def fill_location_score_2(df):\n",
    "    df['prop_location_score2'] = df.groupby('prop_id')['prop_location_score2'].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df\n",
    "\n",
    "# adds a normalised version of a column based on a chosen grouping.\n",
    "def add_normalized_column(df, col, group):\n",
    "    df['norm_' + str(col) + \"_\" + str(group)] = (\n",
    "        (df[col] - df.groupby(group)[col].transform('mean')) \n",
    "        / df.groupby(group)[col].transform('std')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def prep_data(df, target_cols, test=False):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    print('add hour, day, month')\n",
    "    df_new = date_time(df_new)\n",
    "    #df_new = remove_cols_nan(df_new, 0.9)\n",
    "    \n",
    "    # difference features assumes that users purchase in same category as history.\n",
    "    print('add difference features')\n",
    "    df_new['usd_diff'] = df_new['visitor_hist_adr_usd'] - df_new['price_usd']\n",
    "    df_new['star_diff'] = df_new['visitor_hist_starrating'] - df_new['prop_starrating']    \n",
    "    df_new['log_price_diff'] = df_new['prop_log_historical_price'] - np.log(df_new['price_usd'])\n",
    "    \n",
    "    # count variables \n",
    "    # theory: A property that is in more searches is purchased more often.\n",
    "    df_new['prop_id_count'] = df.groupby('prop_id')['prop_id'].transform('count')\n",
    "    \n",
    "    print(\"fill ls2\")\n",
    "    #df_new = fill_location_score_2(df_new)\n",
    "    \n",
    "    # ranking features\n",
    "    print('add rank features')\n",
    "    df_new = create_rank_feature(df_new, 'usd_diff')\n",
    "    df_new = create_rank_feature(df_new, 'price_usd')\n",
    "    df_new = create_rank_feature(df_new, 'prop_starrating')\n",
    "    df_new = create_rank_feature(df_new, 'prop_review_score')\n",
    "    df_new = create_rank_feature(df_new, 'prop_location_score1')\n",
    "    df_new = create_rank_feature(df_new, 'prop_location_score2')\n",
    "    \n",
    "    # Fill distance with mean.\n",
    "    df['orig_destination_distance'].fillna(df['orig_destination_distance'].mean(),inplace=True)\n",
    "    \n",
    "    \n",
    "    print(\"remove nan\")\n",
    "    # Fill rest of nan values with lowest.\n",
    "    for i in df_new.columns[df_new.isnull().any(axis=0)]:\n",
    "        df_new[i].fillna(0,inplace=True)\n",
    "    \n",
    "    print('add normalised features')\n",
    "    groups = ['srch_id', 'prop_country_id', 'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window', 'month']\n",
    "    targets = ['price_usd', 'prop_starrating', 'prop_review_score', 'prop_location_score1', 'prop_location_score2']\n",
    "    for group in groups:\n",
    "        for target in targets:\n",
    "            df_new = add_normalized_column(df_new, target, group)\n",
    "   \n",
    "    df_new = add_normalized_column(df_new, 'price_usd', 'prop_id')\n",
    "    df_new = add_normalized_column(df_new, 'price_usd', 'srch_room_count')\n",
    "    \n",
    "    if not test:\n",
    "        print('add score')\n",
    "        df_new = make_score(df_new)\n",
    "        df_new = df_new.drop(target_cols, axis=1)\n",
    "        \n",
    "    # Normalisation might create nans\n",
    "    print(\"remove nan\\n\")\n",
    "    for i in df_new.columns[df_new.isnull().any(axis=0)]:\n",
    "        df_new[i].fillna(0,inplace=True)\n",
    "        \n",
    "    for c in categorical_features:\n",
    "        df_new[c] = df_new[c].astype('category')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4d6eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepping test data\n",
      "add hour, day, month\n",
      "add difference features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hrvanelderen/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill ls2\n",
      "add rank features\n",
      "remove nan\n",
      "add normalised features\n",
      "Add distance from mean booking\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'usd_diff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'usd_diff'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisitor_location_country_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop_country_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrepping test data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df_test \u001b[38;5;241m=\u001b[39m \u001b[43mprep_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrepping training data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m df_train \u001b[38;5;241m=\u001b[39m prep_data(df_train, target_cols, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 100\u001b[0m, in \u001b[0;36mprep_data\u001b[0;34m(df, target_cols, test)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdd distance from mean booking\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[0;32m--> 100\u001b[0m     df_new \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dist_mean_booking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m test:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m, in \u001b[0;36mcreate_dist_mean_booking\u001b[0;34m(df, col)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dist_mean_booking\u001b[39m(df, col):\n\u001b[0;32m---> 45\u001b[0m     df[\u001b[38;5;28mstr\u001b[39m(col) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_dist_mean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(df[col] \u001b[38;5;241m-\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbooking_bool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1246\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m--> 967\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m    970\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    973\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m    974\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py:4041\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[0;32m-> 4041\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4042\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4043\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'usd_diff'"
     ]
    }
   ],
   "source": [
    "target_cols = ['click_bool', 'booking_bool', 'gross_bookings_usd', 'position']\n",
    "categorical_features = ['hour', 'day', 'month', 'site_id', 'visitor_location_country_id', 'prop_country_id', 'prop_id', 'srch_destination_id']\n",
    "\n",
    "print(\"Prepping test data\")\n",
    "df_test = prep_data(df_test, target_cols, True)\n",
    "print(\"Prepping training data\")\n",
    "df_train = prep_data(df_train, target_cols, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebedf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da28ce6",
   "metadata": {},
   "source": [
    "<h1>Data split<h1\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daeec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=0.2, n_splits=2, random_state = 7)\n",
    "split = splitter.split(df_train, groups=df_train['srch_id'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "df_ideal = df_train.iloc[test_inds].copy().sort_values(by=['srch_id', 'score'], ascending=[True, False], inplace=False)\n",
    "\n",
    "X = df_train.drop(['score'], axis=1)\n",
    "y = df_train['score']\n",
    "\n",
    "X_train, X_test, y_train, y_test, test_ideal = X.iloc[train_inds], X.iloc[test_inds], y.iloc[train_inds], y.iloc[test_inds], df_ideal\n",
    "\n",
    "train_groups = X_train.groupby('srch_id').size().to_frame('size')['size'].to_numpy()\n",
    "\n",
    "test_groups = X_test.groupby('srch_id').size().to_frame('size')['size'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2360896",
   "metadata": {},
   "source": [
    "<h1>Training <h1\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d562c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\":\"ndcg\",\n",
    "    'n_estimators': 500, \n",
    "    'max_depth': 10, \n",
    "    'learning_rate': 0.08925380432712779, \n",
    "    'subsample': 0.523890758165789, \n",
    "    'colsample_bytree': 0.5433556425106324, \n",
    "    'feature_fraction': 0.9677058301342538,\n",
    "    'reg_alpha': 0.00011669441178850782, \n",
    "    'reg_lambda': 0.008250891056480582\n",
    "}\n",
    "\n",
    "ranker = lgb.LGBMRanker(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f71f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    group=train_groups,\n",
    "    eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "    eval_group=[train_groups, test_groups],\n",
    "    eval_at=[5],\n",
    "    feature_name='auto', \n",
    "    categorical_feature = 'auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844703d3",
   "metadata": {},
   "source": [
    "<h1> Validation <h1\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pred_ideal(df_in, df_ideal, y_pred):\n",
    "    df = df_in.copy()\n",
    "    df['pred_grades'] = y_pred\n",
    "    df = df.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "\n",
    "    # Merge grades from ideal on srch_id and prop_id\n",
    "    df = df.merge(df_ideal, on=['srch_id', 'prop_id'], how='left')\n",
    "\n",
    "    # Return srch_id, prop_id and pred_grades\n",
    "    return df[['srch_id', 'prop_id', 'pred_grades', 'score']]\n",
    "\n",
    "def construct_pred_submission(df_in, y_pred):\n",
    "    df = df_in.copy()\n",
    "    df['pred_grades'] = y_pred\n",
    "    df = df.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "\n",
    "    # Return srch_id, prop_id and pred_grades\n",
    "    return df[['srch_id', 'prop_id']]\n",
    "\n",
    "def constructs_predictions(model, data, ideal_df = None):\n",
    "    y_pred = model.predict(data)\n",
    "\n",
    "    if ideal_df is not None:\n",
    "        pred_df = construct_pred_ideal(data, ideal_df, y_pred)\n",
    "    else:\n",
    "        pred_df = construct_pred_submission(data, y_pred)\n",
    "    return pred_df\n",
    "\n",
    "def calc_NDCG(df_ideal, df_pred, k = 5):\n",
    "    # Group by 5\n",
    "    df_ideal = df_ideal.groupby('srch_id').head(k)\n",
    "    df_pred = df_pred.groupby('srch_id').head(k)\n",
    "\n",
    "    assert df_ideal.shape[0] % k == 0\n",
    "    assert df_pred.shape[0] % k == 0\n",
    "    \n",
    "    # Get grades matrices\n",
    "    ideal_grades = df_ideal['score'].values.reshape(int(df_ideal.shape[0] / k), k)\n",
    "    pred_grades = df_pred['score'].values.reshape(int(df_pred.shape[0] / k), k)\n",
    "\n",
    "    discount_vec = [1/np.log2(i+2) for i in range(k)]\n",
    "\n",
    "    # Calculate NDCG\n",
    "    NDCG = (pred_grades @ discount_vec).sum() / (ideal_grades @ discount_vec).sum()\n",
    "\n",
    "    return NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgbm = constructs_predictions(ranker, X_test, ideal_df=test_ideal)\n",
    "pred_random = construct_pred_ideal(X_test, test_ideal, np.random.rand(len(X_test)))\n",
    "pred_lgbm_submission = constructs_predictions(ranker, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6078aa",
   "metadata": {},
   "source": [
    "Highest score: 0.4175907881212144\n",
    "\n",
    "0.4189784476024323 \n",
    "\n",
    "0.41756318918996455 added rank_diff usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ac91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"LGBM: {calc_NDCG(test_ideal, pred_lgbm)},\\nRandom: {calc_NDCG(test_ideal, pred_random)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgbm_submission.to_csv('../data/submission_LGBM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4374de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(ranker, figsize = (12,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14356d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
