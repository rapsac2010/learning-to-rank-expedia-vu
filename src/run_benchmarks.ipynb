{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "from helpers.helper_functions import *\n",
    "from helpers.helper_classes import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_prepare_results(y_pred, X_test, test_ideal):\n",
    "    df_res = X_test.copy()\n",
    "    df_res['pred_grades'] = y_pred\n",
    "    df_res = df_res.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "    df_res = df_res.merge(test_ideal, on=['srch_id', 'prop_id'], how='left')\n",
    "\n",
    "    ndcg = calc_NDCG(test_ideal, df_res)\n",
    "    print(f\"result final:{ndcg}\")\n",
    "\n",
    "    return ndcg, df_res\n",
    "\n",
    "def fill_nan_except(df, fill_value, exclude_cols, replace_inf=False):\n",
    "    # Get the list of columns to fill NaNs\n",
    "    fill_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    # Fill NaNs with the specified value in the fill_cols\n",
    "    df[fill_cols] = df[fill_cols].fillna(fill_value)\n",
    "    \n",
    "    # Replace infinite values if specified\n",
    "    if replace_inf:\n",
    "        df = df.replace([np.inf, -np.inf], fill_value)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_top_features(df, feature_imp, n_features):\n",
    "    # Get n_features most important features from feature importance and subset df\n",
    "    features = feature_imp.iloc[:n_features]['Feature'].tolist()\n",
    "    # insert srch_id to features\n",
    "    features.insert(0, 'srch_id')\n",
    "    \n",
    "    subset_df = df[features]\n",
    "    return subset_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('src/config.ini')\n",
    "os.chdir(config['PATH']['ROOT_DIR'])\n",
    "\n",
    "# # Load data\n",
    "df = pd.read_parquet(config['PATH']['INT_DIR'] + '/training_set_preprocessed_nodrop.parquet', engine = 'auto')\n",
    "df_test = pd.read_parquet(config['PATH']['INT_DIR'] + '/test_set_preprocessed_nodrop.parquet', engine = 'auto')\n",
    "df_mini = df.sample(frac=0.1, random_state=7)\n",
    "\n",
    "feature_imp = pd.read_csv(config['PATH']['INT_DIR'] + '/feature_importance.csv', index_col=0)\n",
    "\n",
    "categorical_features = ['hour', 'day', 'month', 'day_of_week', 'site_id', 'visitor_location_country_id', 'prop_country_id', 'prop_id', 'srch_destination_id']\n",
    "\n",
    "for c in categorical_features:\n",
    "    df[c] = df[c].astype('category')\n",
    "    df_test[c] = df_test[c].astype('category')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\src\\helpers\\helper_functions.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.sort_values(by=['srch_id', target_str], ascending=[True, False], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_feature, X_train, X_test, y_feature, y_train, y_test, test_ideal = train_val_test_split(df, 'target', test_size=.15, val_size=.03, random_state=7)\n",
    "\n",
    "_, desire_df_click = construct_desire(X_feature)\n",
    "_, desire_df_book = construct_desire(X_feature, target = 'booking_bool')\n",
    "\n",
    "prop_counts = X_feature['prop_id'].value_counts()\n",
    "prop_counts.name = 'prop_counts'\n",
    "prop_counts = pd.DataFrame({'prop_id':prop_counts.index, 'count':prop_counts.values})\n",
    "\n",
    "srch_dest_counts = X_feature['srch_destination_id'].value_counts()\n",
    "srch_dest_counts.name = 'srch_dest_counts'\n",
    "srch_dest_counts = pd.DataFrame({'srch_destination_id':srch_dest_counts.index, 'count':srch_dest_counts.values})\n",
    "\n",
    "merge_df_list = [(desire_df_click, 'prop_id'), (desire_df_book, 'prop_id'), (prop_counts, 'prop_id'), (srch_dest_counts, 'srch_destination_id')]   \n",
    "\n",
    "X_train_int = merge_and_drop(X_train, merge_df_list)\n",
    "X_test_int = merge_and_drop(X_test, merge_df_list)\n",
    "\n",
    "\n",
    "\n",
    "# Fill na's for all columns but: ['hour', 'day', 'month', 'day_of_week', 'site_id', 'visitor_location_country_id', 'prop_country_id', 'prop_id', 'srch_destination_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caspa\\AppData\\Local\\Temp\\ipykernel_3528\\222179639.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[fill_cols] = df[fill_cols].fillna(fill_value)\n",
      "C:\\Users\\caspa\\AppData\\Local\\Temp\\ipykernel_3528\\222179639.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[fill_cols] = df[fill_cols].fillna(fill_value)\n"
     ]
    }
   ],
   "source": [
    "X_train = get_top_features(X_train_int, feature_imp, 25)\n",
    "X_test = get_top_features(X_test_int, feature_imp, 25)\n",
    "\n",
    "X_train = fill_nan_except(X_train, 0, categorical_features, replace_inf=True)\n",
    "X_test = fill_nan_except(X_test, 0, categorical_features, replace_inf=True)\n",
    "\n",
    "# # Random order of X_test\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "X_test = X_test.sample(frac=1, random_state=7)\n",
    "y_test = y_test.loc[X_test.index]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 30)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    leaf_size = trial.suggest_int('leaf_size', 1, 50)\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "\n",
    "    params = {\n",
    "        'n_neighbors': n_neighbors,\n",
    "        'weights': weights,\n",
    "        'algorithm': algorithm,\n",
    "        'leaf_size': leaf_size,\n",
    "        'p': p\n",
    "    }\n",
    "\n",
    "    wandb.init(project='DMT-2023', group = 'KNN_optuna_day2', config = params, reinit = True, allow_val_change=True)\n",
    "\n",
    "    knn = KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        algorithm=algorithm,\n",
    "        leaf_size=leaf_size,\n",
    "        p=p\n",
    "    )\n",
    "\n",
    "    knn.fit(X_train.drop(['srch_id'], axis=1), y_train)\n",
    "    pred_knn = knn.predict(X_test.drop(['srch_id'], axis=1))\n",
    "    ndcg_knn, _ = calculate_ndcg_prepare_results(pred_knn, X_test, test_ideal)\n",
    "\n",
    "    wandb.log({'ndcg_final': ndcg_knn})\n",
    "    wandb.finish()\n",
    "    return ndcg_knn\n",
    "\n",
    "print(\"Running optuna study...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Save params to txt\n",
    "with open('paramsknn.txt', 'w') as f:\n",
    "    print(f\"  Value: {trial.value}\", file=f)\n",
    "    print(\"  Params: \", file=f)\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\", file=f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "Done fitting\n",
      "Predicting...\n",
      "Done predicting\n",
      "result final:0.3697587048324351\n",
      "result final:0.3697587048324351\n"
     ]
    }
   ],
   "source": [
    "# Random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "params_rf = {'n_estimators': 872, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True, 'random_state': 42, 'n_jobs': -1}\n",
    "\n",
    "rf = RandomForestRegressor(**params_rf)\n",
    "print(\"Fitting...\")\n",
    "rf.fit(X_train.drop(['srch_id'], axis=1), y_train)\n",
    "print(\"Done fitting\")\n",
    "print(\"Predicting...\")\n",
    "pred_rf = rf.predict(X_test.drop(['srch_id'], axis=1))\n",
    "print(\"Done predicting\")\n",
    "\n",
    "ndcg_rf, df_res_rf = calculate_ndcg_prepare_results(pred_rf, X_test, test_ideal)\n",
    "print(f\"result final:{ndcg_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 5)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt'])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'max_features': max_features,\n",
    "        'bootstrap': bootstrap,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    wandb.init(project='DMT-2023', group = 'Random_forest_optuna', config = params, reinit = True, allow_val_change=True)\n",
    "\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Assuming your calculate_ndcg_prepare_results function is something similar to the ndcg_score \n",
    "    # And also assuming you are returning ndcg_score from calculate_ndcg_prepare_results\n",
    "    # Adjust this as per your implementation of calculate_ndcg_prepare_results function\n",
    "    rf.fit(X_train.drop(['srch_id'], axis=1), y_train)\n",
    "    pred_rf = rf.predict(X_test.drop(['srch_id'], axis=1))\n",
    "    ndcg_rf, _ = calculate_ndcg_prepare_results(pred_rf, X_test, test_ideal)\n",
    "\n",
    "    wandb.log({'ndcg_final': ndcg_rf})\n",
    "    wandb.finish()\n",
    "    return ndcg_rf\n",
    "\n",
    "print(\"Running optuna study...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Save params to txt\n",
    "with open('paramsrf.txt', 'w') as f:\n",
    "    print(f\"  Value: {trial.value}\", file=f)\n",
    "    print(\"  Params: \", file=f)\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\", file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
