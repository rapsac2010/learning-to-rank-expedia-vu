{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import os\n",
    "from joblib import dump, load\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from helpers.helper_functions import *\n",
    "from helpers.helper_classes import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "import numpy as np\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import scienceplots\n",
    "import latex\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.style.use(['science', 'ieee'])\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('src/config.ini')\n",
    "\n",
    "# Read data\n",
    "df_og = load(config['PATH']['DATA_DIR'] + '/full_df_daily_cap95.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct target as bad (0-6), okay (6-8), good (8-10)\n",
    "df = df_og.copy()\n",
    "# df = df.drop(columns = ['time'])\n",
    "df['target'] = df['target'].apply(lambda x: 0 if x < 7 else 1)\n",
    "\n",
    "# Impute outliers (larger than 1.5 IQR) with mean of column in all _sum columns\n",
    "# for col in df.columns:\n",
    "#     if col.endswith('_sum'):\n",
    "#         df[col] = df[col].mask(df[col] > df[col].quantile(0.75) + 1.5 * (df[col].quantile(0.75) - df[col].quantile(0.25)), df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=['target'], axis = 1), df['target']\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_ts(X, y, split_ratios=[0.5, 0.2])\n",
    "\n",
    "# Full train set for final model\n",
    "X_train_full = pd.concat([X_train, X_val])\n",
    "y_train_full = pd.concat([y_train, y_val])\n",
    "\n",
    "# Get non-dummy columns\n",
    "if len([var for var in df.columns if var.startswith('day')]) == 7:\n",
    "    df = df.drop(columns=['day_of_week_0'])\n",
    "dummy_cols = [var for var in df.columns if var.startswith('day')] + ['target', 'activity_idc', 'call_idc', 'sms_idc', 'id']\n",
    "cols_no_dummy = [var for var in X_train.columns if var not in dummy_cols]\n",
    "\n",
    "# Scale data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ct = ColumnTransformer([('scaler', StandardScaler(), cols_no_dummy)], remainder='passthrough')\n",
    "ct.set_output(transform='pandas')\n",
    "X_train_scaled = ct.fit_transform(X_train)\n",
    "X_val_scaled = ct.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_lstm(X, y, seq_length):\n",
    "    import numpy as np\n",
    "\n",
    "    X_lstm = []\n",
    "    y_lstm = []\n",
    "    \n",
    "    # Iterate over persons:\n",
    "    for person in X['remainder__id'].unique():\n",
    "        # Get all days for this person\n",
    "        X_person = X[X['remainder__id'] == person].drop(columns = ['remainder__id']).values\n",
    "        y_person = y[X['remainder__id'] == person].drop(columns = ['remainder__id']).values\n",
    "\n",
    "        i = 0\n",
    "        while i < len(X_person):\n",
    "            # If days are less than seq_length, pad with zeros at the beginning of X\n",
    "            if len(X_person) < seq_length:\n",
    "                n_missing = seq_length - len(X_person)\n",
    "                X_padded = np.pad(X_person, ((n_missing, 0), (0, 0)), mode='constant', constant_values=0)\n",
    "                X_lstm.append(X_padded)\n",
    "                y_lstm.append(y_person[-1])\n",
    "                break\n",
    "\n",
    "            # If days are more than seq_length, create sequences of seq_length days\n",
    "            elif i + seq_length <= len(X_person):\n",
    "                X_lstm.append(X_person[i:i+seq_length])\n",
    "                y_lstm.append(y_person[i+seq_length-1])\n",
    "                i += 1\n",
    "\n",
    "            # If the remaining days are not enough to form a full sequence, stop iterating\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        # Add sequenced data for this person to the list of all sequences\n",
    "\n",
    "    # Convert lists to numpy arrays and reshape y_lstm\n",
    "    X_lstm = np.array(X_lstm).astype('float32'\t)\n",
    "    y_lstm = np.array(y_lstm).reshape(-1, 1).astype('float32')\n",
    "\n",
    "    # Return full sequenced dataframe\n",
    "    return X_lstm, y_lstm\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "def build_lstm_model(input_shape, hunits = 128):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hunits, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 7\n",
    "X_lstm_train, y_lstm_train = shape_lstm(X_train_scaled, y_train, seq_length=seq_length)\n",
    "X_lstm_val, y_lstm_val = shape_lstm(X_val_scaled, y_val, seq_length=seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 16:59:16,443]\u001b[0m A new study created in memory with name: no-name-d85f60d7-fc45-40d6-9394-a296eb81202d\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 16:59:27,048]\u001b[0m Trial 0 finished with value: 0.698113203048706 and parameters: {'hunits': 96, 'epochs': 40}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 16:59:34,175]\u001b[0m Trial 1 finished with value: 0.5849056839942932 and parameters: {'hunits': 192, 'epochs': 25}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 16:59:38,896]\u001b[0m Trial 2 finished with value: 0.6415094137191772 and parameters: {'hunits': 48, 'epochs': 10}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 16:59:46,408]\u001b[0m Trial 3 finished with value: 0.6603773832321167 and parameters: {'hunits': 16, 'epochs': 35}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A005AFE2A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 16:59:55,718]\u001b[0m Trial 4 finished with value: 0.6226415038108826 and parameters: {'hunits': 160, 'epochs': 30}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A005C7A660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 17:00:03,735]\u001b[0m Trial 5 finished with value: 0.6037735939025879 and parameters: {'hunits': 16, 'epochs': 40}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:00:10,661]\u001b[0m Trial 6 finished with value: 0.6603773832321167 and parameters: {'hunits': 224, 'epochs': 10}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:00:15,348]\u001b[0m Trial 7 finished with value: 0.6415094137191772 and parameters: {'hunits': 48, 'epochs': 10}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:00:22,747]\u001b[0m Trial 8 finished with value: 0.6415094137191772 and parameters: {'hunits': 80, 'epochs': 25}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:00:29,269]\u001b[0m Trial 9 finished with value: 0.6415094137191772 and parameters: {'hunits': 112, 'epochs': 15}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:00:50,128]\u001b[0m Trial 10 finished with value: 0.6226415038108826 and parameters: {'hunits': 256, 'epochs': 40}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:00:59,347]\u001b[0m Trial 11 finished with value: 0.698113203048706 and parameters: {'hunits': 112, 'epochs': 35}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:01:07,521]\u001b[0m Trial 12 finished with value: 0.6603773832321167 and parameters: {'hunits': 128, 'epochs': 35}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:01:15,578]\u001b[0m Trial 13 finished with value: 0.6603773832321167 and parameters: {'hunits': 96, 'epochs': 35}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:01:23,326]\u001b[0m Trial 14 finished with value: 0.6792452931404114 and parameters: {'hunits': 160, 'epochs': 20}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:01:29,791]\u001b[0m Trial 15 finished with value: 0.6037735939025879 and parameters: {'hunits': 80, 'epochs': 30}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:01:41,721]\u001b[0m Trial 16 finished with value: 0.6037735939025879 and parameters: {'hunits': 160, 'epochs': 40}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:01:50,289]\u001b[0m Trial 17 finished with value: 0.6603773832321167 and parameters: {'hunits': 128, 'epochs': 30}. Best is trial 0 with value: 0.698113203048706.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:01:57,491]\u001b[0m Trial 18 finished with value: 0.7358490824699402 and parameters: {'hunits': 48, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:04,139]\u001b[0m Trial 19 finished with value: 0.6603773832321167 and parameters: {'hunits': 48, 'epochs': 20}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:08,735]\u001b[0m Trial 20 finished with value: 0.6226415038108826 and parameters: {'hunits': 64, 'epochs': 5}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:18,204]\u001b[0m Trial 21 finished with value: 0.6415094137191772 and parameters: {'hunits': 96, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:25,796]\u001b[0m Trial 22 finished with value: 0.6792452931404114 and parameters: {'hunits': 96, 'epochs': 40}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:31,802]\u001b[0m Trial 23 finished with value: 0.7169811129570007 and parameters: {'hunits': 32, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:38,386]\u001b[0m Trial 24 finished with value: 0.6226415038108826 and parameters: {'hunits': 32, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:45,942]\u001b[0m Trial 25 finished with value: 0.6037735939025879 and parameters: {'hunits': 64, 'epochs': 25}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:02:54,122]\u001b[0m Trial 26 finished with value: 0.7169811129570007 and parameters: {'hunits': 32, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:03:03,736]\u001b[0m Trial 27 finished with value: 0.6226415038108826 and parameters: {'hunits': 16, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:03:10,949]\u001b[0m Trial 28 finished with value: 0.6792452931404114 and parameters: {'hunits': 32, 'epochs': 25}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:03:18,479]\u001b[0m Trial 29 finished with value: 0.6792452931404114 and parameters: {'hunits': 32, 'epochs': 20}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:03:26,538]\u001b[0m Trial 30 finished with value: 0.6603773832321167 and parameters: {'hunits': 64, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:03:34,339]\u001b[0m Trial 31 finished with value: 0.6415094137191772 and parameters: {'hunits': 48, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:03:45,990]\u001b[0m Trial 32 finished with value: 0.6037735939025879 and parameters: {'hunits': 80, 'epochs': 40}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:03:55,454]\u001b[0m Trial 33 finished with value: 0.6603773832321167 and parameters: {'hunits': 32, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:04:00,963]\u001b[0m Trial 34 finished with value: 0.6603773832321167 and parameters: {'hunits': 16, 'epochs': 25}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:04:10,791]\u001b[0m Trial 35 finished with value: 0.6037735939025879 and parameters: {'hunits': 64, 'epochs': 40}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:04:18,868]\u001b[0m Trial 36 finished with value: 0.5471698045730591 and parameters: {'hunits': 16, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:04:27,549]\u001b[0m Trial 37 finished with value: 0.6603773832321167 and parameters: {'hunits': 48, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:04:36,324]\u001b[0m Trial 38 finished with value: 0.698113203048706 and parameters: {'hunits': 80, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:04:50,498]\u001b[0m Trial 39 finished with value: 0.6415094137191772 and parameters: {'hunits': 192, 'epochs': 40}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:04:59,885]\u001b[0m Trial 40 finished with value: 0.6226415038108826 and parameters: {'hunits': 32, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:08,843]\u001b[0m Trial 41 finished with value: 0.6415094137191772 and parameters: {'hunits': 112, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:16,126]\u001b[0m Trial 42 finished with value: 0.5849056839942932 and parameters: {'hunits': 112, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:24,436]\u001b[0m Trial 43 finished with value: 0.6603773832321167 and parameters: {'hunits': 144, 'epochs': 40}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:31,145]\u001b[0m Trial 44 finished with value: 0.6037735939025879 and parameters: {'hunits': 192, 'epochs': 30}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:38,750]\u001b[0m Trial 45 finished with value: 0.6415094137191772 and parameters: {'hunits': 144, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:43,882]\u001b[0m Trial 46 finished with value: 0.6226415038108826 and parameters: {'hunits': 96, 'epochs': 25}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:47,790]\u001b[0m Trial 47 finished with value: 0.6603773832321167 and parameters: {'hunits': 64, 'epochs': 15}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:05:54,225]\u001b[0m Trial 48 finished with value: 0.6037735939025879 and parameters: {'hunits': 80, 'epochs': 40}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n",
      "\u001b[32m[I 2023-04-20 17:06:02,112]\u001b[0m Trial 49 finished with value: 0.6226415038108826 and parameters: {'hunits': 176, 'epochs': 35}. Best is trial 18 with value: 0.7358490824699402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 18, Accuracy: 0.7358490824699402\n",
      "Best params: {'hunits': 48, 'epochs': 35}\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for the optimization\n",
    "def objective(trial: Trial):\n",
    "    hidden_units = trial.suggest_int('hunits', 16, 256, step=16)\n",
    "    epochs = trial.suggest_int('epochs', 5, 40, step=5)\n",
    "\n",
    "\n",
    "    input_shape = (seq_length, X_lstm_train.shape[2])\n",
    "    model = build_lstm_model(input_shape, hidden_units)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_lstm_train, y_lstm_train, epochs=epochs, verbose=0)\n",
    "    score = model.evaluate(X_lstm_val, y_lstm_val, verbose=0)\n",
    "\n",
    "    return score[1]\n",
    "\n",
    "# Optimize the pipeline using Optuna\n",
    "manual_seed = 42\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "tf.random.set_seed(manual_seed)\n",
    "sampler = TPESampler(seed=manual_seed)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best trial\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial: {best_trial.number}, Accuracy: {best_trial.value}\")\n",
    "print(f\"Best params: {best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_50 (LSTM)              (None, 48)                18432     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 49        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,481\n",
      "Trainable params: 18,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "21/21 [==============================] - 3s 5ms/step - loss: 0.6352 - accuracy: 0.6357\n",
      "Epoch 2/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7271\n",
      "Epoch 3/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7349\n",
      "Epoch 4/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7442\n",
      "Epoch 5/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7504\n",
      "Epoch 6/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7581\n",
      "Epoch 7/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7628\n",
      "Epoch 8/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7783\n",
      "Epoch 9/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7798\n",
      "Epoch 10/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7891\n",
      "Epoch 11/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7922\n",
      "Epoch 12/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8062\n",
      "Epoch 13/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8140\n",
      "Epoch 14/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8295\n",
      "Epoch 15/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8171\n",
      "Epoch 16/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8341\n",
      "Epoch 17/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8310\n",
      "Epoch 18/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8326\n",
      "Epoch 19/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3219 - accuracy: 0.8543\n",
      "Epoch 20/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8481\n",
      "Epoch 21/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8605\n",
      "Epoch 22/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.8667\n",
      "Epoch 23/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8636\n",
      "Epoch 24/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.8651\n",
      "Epoch 25/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.8822\n",
      "Epoch 26/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.8868\n",
      "Epoch 27/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.8899\n",
      "Epoch 28/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9023\n",
      "Epoch 29/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.2211 - accuracy: 0.9085\n",
      "Epoch 30/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9163\n",
      "Epoch 31/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9178\n",
      "Epoch 32/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9132\n",
      "Epoch 33/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9380\n",
      "Epoch 34/35\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9349\n",
      "Epoch 35/35\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9287\n",
      "8/8 [==============================] - 2s 3ms/step\n",
      "Test loss: 1.028864860534668\n",
      "Test accuracy: 0.6468085050582886\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m# Print the confusion matrix\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m---> 29\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     32\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(y_pred)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Train the model on the full training set\n",
    "ct = ColumnTransformer([('scaler', StandardScaler(), cols_no_dummy)], remainder='passthrough')\n",
    "ct.set_output(transform='pandas')\n",
    "\n",
    "X_train_full_scaled = ct.fit_transform(X_train_full)\n",
    "X_test_scaled = ct.transform(X_test)\n",
    "\n",
    "X_train_full_lstm, y_train_full_lstm = shape_lstm(X_train_full_scaled, y_train_full, seq_length=7)\n",
    "X_test_lstm, y_test_lstm = shape_lstm(X_test_scaled, y_test, seq_length=7)\n",
    "\n",
    "# Set the input_shape for your model based on your input data\n",
    "input_shape = (seq_length, X_train_full_lstm.shape[2])\n",
    "model2 = build_lstm_model(input_shape, hunits=best_trial.params['hunits'])\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "hist_full = model2.fit(X_train_full_lstm, y_train_full_lstm, epochs=best_trial.params['epochs'], batch_size=32)\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model2.predict(X_test_lstm)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model2.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = np.round(y_pred)\n",
    "cm = confusion_matrix(y_test_lstm, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('figures/lstm_confusion_matrix.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x\n",
       "0  2.0\n",
       "1  3.0\n",
       "2  4.0\n",
       "3  NaN"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe with x = 1,2,3,4\n",
    "df = pd.DataFrame({'x': [1,2,3,4]})\n",
    "df.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.56      0.62       108\n",
      "         1.0       0.68      0.77      0.72       127\n",
      "\n",
      "    accuracy                           0.68       235\n",
      "   macro avg       0.68      0.67      0.67       235\n",
      "weighted avg       0.68      0.68      0.67       235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_lstm, y_pred.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
