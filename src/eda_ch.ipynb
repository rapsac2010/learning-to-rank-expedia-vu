{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import os\n",
    "from joblib import dump, load\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from helpers.helper_functions import *\n",
    "from helpers.helper_classes import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('src/config.ini')\n",
    "# os.chdir(config['PATH']['ROOT_DIR'])\n",
    "\n",
    "# # Load data\n",
    "df = pd.read_parquet(config['PATH']['DATA_DIR'] + '/training_set.parquet', engine = 'fastparquet')\n",
    "df_test = pd.read_parquet(config['PATH']['DATA_DIR'] + '/test_set.parquet', engine = 'fastparquet')\n",
    "\n",
    "# mini df for testing quickly \n",
    "df_mini = df[df['srch_id'] < 10000]\n",
    "# df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# time to datetime\n",
    "# df['time'] = pd.to_datetime(df['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_target(row):\n",
    "    if row['booking_bool'] == 1:\n",
    "        return 5\n",
    "    elif row['click_bool'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def binary_target(row):\n",
    "    if row['booking_bool'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def construct_target_df(df):\n",
    "    df.loc[:, 'target'] = np.zeros(len(df))\n",
    "    df.loc[df['click_bool'] == 1, 'target'] = 1\n",
    "    df.loc[df['booking_bool'] == 1, 'target'] = 5\n",
    "    return df['target']\n",
    "\n",
    "def drop_cols(df, cols):\n",
    "    return df.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>prop_location_score2</th>\n",
       "      <th>prop_log_historical_price</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_length_of_stay</th>\n",
       "      <th>srch_booking_window</th>\n",
       "      <th>srch_adults_count</th>\n",
       "      <th>srch_children_count</th>\n",
       "      <th>srch_room_count</th>\n",
       "      <th>srch_saturday_night_bool</th>\n",
       "      <th>srch_query_affinity_score</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>random_bool</th>\n",
       "      <th>comp1_rate</th>\n",
       "      <th>comp1_inv</th>\n",
       "      <th>comp1_rate_percent_diff</th>\n",
       "      <th>comp2_rate</th>\n",
       "      <th>comp2_inv</th>\n",
       "      <th>comp2_rate_percent_diff</th>\n",
       "      <th>comp3_rate</th>\n",
       "      <th>comp3_inv</th>\n",
       "      <th>comp3_rate_percent_diff</th>\n",
       "      <th>comp4_rate</th>\n",
       "      <th>comp4_inv</th>\n",
       "      <th>comp4_rate_percent_diff</th>\n",
       "      <th>comp5_rate</th>\n",
       "      <th>comp5_inv</th>\n",
       "      <th>comp5_rate_percent_diff</th>\n",
       "      <th>comp6_rate</th>\n",
       "      <th>comp6_inv</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>3180</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>5.03</td>\n",
       "      <td>119.00</td>\n",
       "      <td>0</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>5543</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>4.93</td>\n",
       "      <td>118.00</td>\n",
       "      <td>0</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>14142</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>4.16</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>22393</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>5.03</td>\n",
       "      <td>143.00</td>\n",
       "      <td>0</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>24194</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>4.72</td>\n",
       "      <td>79.00</td>\n",
       "      <td>0</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959178</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>32019</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>4.53</td>\n",
       "      <td>66.07</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959179</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>33959</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>4.39</td>\n",
       "      <td>67.10</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959180</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>35240</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>4.64</td>\n",
       "      <td>73.91</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959181</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>94437</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>4.64</td>\n",
       "      <td>66.07</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959182</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>99509</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>4.64</td>\n",
       "      <td>82.06</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4959183 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id  site_id  visitor_location_country_id   \n",
       "0              1       24                          216  \\\n",
       "1              1       24                          216   \n",
       "2              1       24                          216   \n",
       "3              1       24                          216   \n",
       "4              1       24                          216   \n",
       "...          ...      ...                          ...   \n",
       "4959178   332787       24                          216   \n",
       "4959179   332787       24                          216   \n",
       "4959180   332787       24                          216   \n",
       "4959181   332787       24                          216   \n",
       "4959182   332787       24                          216   \n",
       "\n",
       "         visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id   \n",
       "0                           -1.0                  -1.0              219  \\\n",
       "1                           -1.0                  -1.0              219   \n",
       "2                           -1.0                  -1.0              219   \n",
       "3                           -1.0                  -1.0              219   \n",
       "4                           -1.0                  -1.0              219   \n",
       "...                          ...                   ...              ...   \n",
       "4959178                     -1.0                  -1.0              117   \n",
       "4959179                     -1.0                  -1.0              117   \n",
       "4959180                     -1.0                  -1.0              117   \n",
       "4959181                     -1.0                  -1.0              117   \n",
       "4959182                     -1.0                  -1.0              117   \n",
       "\n",
       "         prop_id  prop_starrating  prop_review_score  prop_brand_bool   \n",
       "0           3180                3                4.5                1  \\\n",
       "1           5543                3                4.5                1   \n",
       "2          14142                2                3.5                1   \n",
       "3          22393                3                4.5                1   \n",
       "4          24194                3                4.5                1   \n",
       "...          ...              ...                ...              ...   \n",
       "4959178    32019                4                3.5                0   \n",
       "4959179    33959                4                3.0                1   \n",
       "4959180    35240                4                0.0                0   \n",
       "4959181    94437                4                0.0                0   \n",
       "4959182    99509                4                4.5                1   \n",
       "\n",
       "         prop_location_score1  prop_location_score2   \n",
       "0                        2.94                0.0691  \\\n",
       "1                        2.64                0.0843   \n",
       "2                        2.71                0.0556   \n",
       "3                        2.40                0.0561   \n",
       "4                        2.94                0.2090   \n",
       "...                       ...                   ...   \n",
       "4959178                  2.48                0.0551   \n",
       "4959179                  2.20                0.3344   \n",
       "4959180                  1.79               -1.0000   \n",
       "4959181                  2.94                0.0928   \n",
       "4959182                  2.08                0.0344   \n",
       "\n",
       "         prop_log_historical_price  price_usd  promotion_flag   \n",
       "0                             5.03     119.00               0  \\\n",
       "1                             4.93     118.00               0   \n",
       "2                             4.16      49.00               0   \n",
       "3                             5.03     143.00               0   \n",
       "4                             4.72      79.00               0   \n",
       "...                            ...        ...             ...   \n",
       "4959178                       4.53      66.07               0   \n",
       "4959179                       4.39      67.10               0   \n",
       "4959180                       4.64      73.91               0   \n",
       "4959181                       4.64      66.07               0   \n",
       "4959182                       4.64      82.06               0   \n",
       "\n",
       "         srch_destination_id  srch_length_of_stay  srch_booking_window   \n",
       "0                      19222                    1                   10  \\\n",
       "1                      19222                    1                   10   \n",
       "2                      19222                    1                   10   \n",
       "3                      19222                    1                   10   \n",
       "4                      19222                    1                   10   \n",
       "...                      ...                  ...                  ...   \n",
       "4959178                19246                    2                    7   \n",
       "4959179                19246                    2                    7   \n",
       "4959180                19246                    2                    7   \n",
       "4959181                19246                    2                    7   \n",
       "4959182                19246                    2                    7   \n",
       "\n",
       "         srch_adults_count  srch_children_count  srch_room_count   \n",
       "0                        2                    0                1  \\\n",
       "1                        2                    0                1   \n",
       "2                        2                    0                1   \n",
       "3                        2                    0                1   \n",
       "4                        2                    0                1   \n",
       "...                    ...                  ...              ...   \n",
       "4959178                  1                    0                1   \n",
       "4959179                  1                    0                1   \n",
       "4959180                  1                    0                1   \n",
       "4959181                  1                    0                1   \n",
       "4959182                  1                    0                1   \n",
       "\n",
       "         srch_saturday_night_bool  srch_query_affinity_score   \n",
       "0                               0                       -1.0  \\\n",
       "1                               0                       -1.0   \n",
       "2                               0                       -1.0   \n",
       "3                               0                       -1.0   \n",
       "4                               0                       -1.0   \n",
       "...                           ...                        ...   \n",
       "4959178                         0                       -1.0   \n",
       "4959179                         0                       -1.0   \n",
       "4959180                         0                       -1.0   \n",
       "4959181                         0                       -1.0   \n",
       "4959182                         0                       -1.0   \n",
       "\n",
       "         orig_destination_distance  random_bool  comp1_rate  comp1_inv   \n",
       "0                             -1.0            0        -1.0       -1.0  \\\n",
       "1                             -1.0            0        -1.0       -1.0   \n",
       "2                             -1.0            0        -1.0       -1.0   \n",
       "3                             -1.0            0        -1.0       -1.0   \n",
       "4                             -1.0            0        -1.0       -1.0   \n",
       "...                            ...          ...         ...        ...   \n",
       "4959178                       -1.0            0        -1.0       -1.0   \n",
       "4959179                       -1.0            0        -1.0       -1.0   \n",
       "4959180                       -1.0            0        -1.0       -1.0   \n",
       "4959181                       -1.0            0        -1.0       -1.0   \n",
       "4959182                       -1.0            0        -1.0       -1.0   \n",
       "\n",
       "         comp1_rate_percent_diff  comp2_rate  comp2_inv   \n",
       "0                           -1.0        -1.0       -1.0  \\\n",
       "1                           -1.0         0.0        0.0   \n",
       "2                           -1.0         0.0        0.0   \n",
       "3                           -1.0         0.0        0.0   \n",
       "4                           -1.0         0.0        0.0   \n",
       "...                          ...         ...        ...   \n",
       "4959178                     -1.0         1.0        0.0   \n",
       "4959179                     -1.0         0.0        0.0   \n",
       "4959180                     -1.0         1.0        0.0   \n",
       "4959181                     -1.0         1.0        0.0   \n",
       "4959182                     -1.0         0.0        0.0   \n",
       "\n",
       "         comp2_rate_percent_diff  comp3_rate  comp3_inv   \n",
       "0                           -1.0        -1.0       -1.0  \\\n",
       "1                           -1.0        -1.0       -1.0   \n",
       "2                           -1.0        -1.0       -1.0   \n",
       "3                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959178                     22.0         1.0        0.0   \n",
       "4959179                     -1.0         0.0        0.0   \n",
       "4959180                     55.0         0.0        0.0   \n",
       "4959181                     43.0         1.0        0.0   \n",
       "4959182                     -1.0         0.0        0.0   \n",
       "\n",
       "         comp3_rate_percent_diff  comp4_rate  comp4_inv   \n",
       "0                           -1.0        -1.0       -1.0  \\\n",
       "1                           -1.0        -1.0       -1.0   \n",
       "2                           -1.0        -1.0       -1.0   \n",
       "3                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959178                    127.0        -1.0        0.0   \n",
       "4959179                     -1.0         0.0        0.0   \n",
       "4959180                     -1.0         0.0        0.0   \n",
       "4959181                     43.0        -1.0        0.0   \n",
       "4959182                     -1.0         0.0        0.0   \n",
       "\n",
       "         comp4_rate_percent_diff  comp5_rate  comp5_inv   \n",
       "0                           -1.0        -1.0       -1.0  \\\n",
       "1                           -1.0        -1.0       -1.0   \n",
       "2                           -1.0         1.0        0.0   \n",
       "3                           -1.0         0.0        0.0   \n",
       "4                           -1.0         0.0        0.0   \n",
       "...                          ...         ...        ...   \n",
       "4959178                     27.0         1.0        0.0   \n",
       "4959179                     16.0         1.0        0.0   \n",
       "4959180                     16.0         0.0        0.0   \n",
       "4959181                     12.0        -1.0        0.0   \n",
       "4959182                     16.0         0.0        0.0   \n",
       "\n",
       "         comp5_rate_percent_diff  comp6_rate  comp6_inv   \n",
       "0                           -1.0        -1.0       -1.0  \\\n",
       "1                           -1.0        -1.0       -1.0   \n",
       "2                           10.0        -1.0       -1.0   \n",
       "3                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959178                     22.0        -1.0       -1.0   \n",
       "4959179                     22.0        -1.0       -1.0   \n",
       "4959180                      3.0        -1.0       -1.0   \n",
       "4959181                     12.0        -1.0       -1.0   \n",
       "4959182                     -1.0        -1.0       -1.0   \n",
       "\n",
       "         comp6_rate_percent_diff  comp7_rate  comp7_inv   \n",
       "0                           -1.0        -1.0       -1.0  \\\n",
       "1                           -1.0        -1.0       -1.0   \n",
       "2                           -1.0        -1.0       -1.0   \n",
       "3                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959178                     -1.0        -1.0       -1.0   \n",
       "4959179                     -1.0        -1.0       -1.0   \n",
       "4959180                     -1.0        -1.0       -1.0   \n",
       "4959181                     -1.0        -1.0       -1.0   \n",
       "4959182                     -1.0        -1.0       -1.0   \n",
       "\n",
       "         comp7_rate_percent_diff  comp8_rate  comp8_inv   \n",
       "0                           -1.0        -1.0       -1.0  \\\n",
       "1                           -1.0        -1.0       -1.0   \n",
       "2                           -1.0        -1.0       -1.0   \n",
       "3                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959178                     -1.0        -1.0       -1.0   \n",
       "4959179                     -1.0        -1.0       -1.0   \n",
       "4959180                     -1.0        -1.0       -1.0   \n",
       "4959181                     -1.0        -1.0       -1.0   \n",
       "4959182                     -1.0        -1.0       -1.0   \n",
       "\n",
       "         comp8_rate_percent_diff  month  day  hour  \n",
       "0                           -1.0      2    2    15  \n",
       "1                           -1.0      2    2    15  \n",
       "2                           -1.0      2    2    15  \n",
       "3                           -1.0      2    2    15  \n",
       "4                           -1.0      2    2    15  \n",
       "...                          ...    ...  ...   ...  \n",
       "4959178                     -1.0      5   21    11  \n",
       "4959179                     -1.0      5   21    11  \n",
       "4959180                     -1.0      5   21    11  \n",
       "4959181                     -1.0      5   21    11  \n",
       "4959182                     -1.0      5   21    11  \n",
       "\n",
       "[4959183 rows x 52 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df_mini.copy()\n",
    "df_t = df_test.copy()\n",
    "\n",
    "print('copied')\n",
    "# Construct target and drop leaky columns\n",
    "\n",
    "construct_target_df(df_1)\n",
    "# df_1['grades'] = construct_target_df(df_1)\n",
    "\n",
    "def drop_cols(df, cols):\n",
    "    # check which cols are in dff\n",
    "    cols = [col for col in cols if col in df.columns]\n",
    "    return df.drop(cols, axis=1)\n",
    "\n",
    "def construct_datetime(df):\n",
    "    df_out = df.copy()\n",
    "    df_out['date_time'] = pd.to_datetime(df_out['date_time'])\n",
    "    df_out['month'] = df_out['date_time'].dt.month\n",
    "    df_out['day'] = df_out['date_time'].dt.day\n",
    "    df_out['hour'] = df_out['date_time'].dt.hour\n",
    "    return df_out\n",
    "\n",
    "def preprocess(df, train_set = True):\n",
    "    leaky_cols = ['click_bool', 'booking_bool', 'gross_bookings_usd', 'position', 'date_time', 'target']\n",
    "\n",
    "    df_out = df.copy()\n",
    "    df_out = construct_datetime(df_out)\n",
    "    if train_set:\n",
    "        df_out['grades'] = construct_target_df(df_out)\n",
    "    df_out = drop_cols(df_out, leaky_cols)\n",
    "    df_out.fillna(-1, inplace=True)\n",
    "    return df_out\n",
    "\n",
    "df_1 = preprocess(df_1)\n",
    "df_t = preprocess(df_t, train_set=False)\n",
    "df_t\n",
    "# # Construct datetime features\n",
    "# df_1 = construct_datetime(df_1)\n",
    "# df_t = construct_datetime(df_t)\n",
    "\n",
    "# df_1.loc[:, 'grades'] = df_1['target']\n",
    "\n",
    "# # Drop leaky columns\n",
    "\n",
    "\n",
    "\n",
    "# leaky_cols = ['click_bool', 'booking_bool', 'gross_bookings_usd', 'position', 'date_time', 'target']\n",
    "# df_1 = drop_cols(df_1, leaky_cols)\n",
    "\n",
    "\n",
    "# ## Test: Drop all columns with NaNs\n",
    "# # df_1 = df_1.dropna(axis=1)\n",
    "# df_1.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# # Construct dummy cols\n",
    "# dummy_cols = ['prop_country_id', 'visitor_location_country_id', 'srch_destination_id']\n",
    "# df_1 = pd.get_dummies(df_1, columns=dummy_cols, drop_first=True)\n",
    "\n",
    "# df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_test_split(df, target_str, test_size=.2):\n",
    "    splitter = GroupShuffleSplit(test_size=test_size, n_splits=2, random_state = 7)\n",
    "    split = splitter.split(df, groups=df['srch_id'])\n",
    "    train_inds, test_inds = next(split)\n",
    "\n",
    "    df_ideal = df.iloc[test_inds].copy().sort_values(by=['srch_id', 'grades'], ascending=[True, False], inplace=False)\n",
    "\n",
    "    X = df_1.drop(['grades'], axis=1)\n",
    "    y = df_1[target_str]\n",
    "    X_train, X_test, y_train, y_test, test_ideal = X.iloc[train_inds], X.iloc[test_inds], y.iloc[train_inds], y.iloc[test_inds], df_ideal, \n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, test_ideal[['srch_id', 'prop_id', 'grades']]\n",
    "\n",
    "def construct_pred_ideal(df_in, df_ideal, y_pred):\n",
    "    df = df_in.copy()\n",
    "    df['pred_grades'] = y_pred\n",
    "    df = df.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "\n",
    "    # Merge grades from ideal on srch_id and prop_id\n",
    "    df = df.merge(df_ideal, on=['srch_id', 'prop_id'], how='left')\n",
    "\n",
    "    # Return srch_id, prop_id and pred_grades\n",
    "    return df[['srch_id', 'prop_id', 'pred_grades', 'grades']]\n",
    "\n",
    "def construct_pred_submission(df_in, y_pred):\n",
    "    df = df_in.copy()\n",
    "    df['pred_grades'] = y_pred\n",
    "    df = df.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "\n",
    "    # Return srch_id, prop_id and pred_grades\n",
    "    return df[['srch_id', 'prop_id']]\n",
    "\n",
    "def constructs_predictions(model, data, ideal_df = None):\n",
    "    y_pred = model.predict_proba(data)\n",
    "    pred_grades = y_pred @ [0, 1, 5]\n",
    "\n",
    "    if ideal_df is not None:\n",
    "        pred_df = construct_pred_ideal(data, test_ideal, pred_grades)\n",
    "    else:\n",
    "        pred_df = construct_pred_submission(data, pred_grades)\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def calc_NDCG(df_ideal, df_pred, k = 5):\n",
    "    # Group by 5\n",
    "    df_ideal = df_ideal.groupby('srch_id').head(k)\n",
    "    df_pred = df_pred.groupby('srch_id').head(k)\n",
    "\n",
    "    assert df_ideal.shape[0] % k == 0\n",
    "    assert df_pred.shape[0] % k == 0\n",
    "    \n",
    "    # Get grades matrices\n",
    "    ideal_grades = df_ideal['grades'].values.reshape(int(df_ideal.shape[0] / k), k)\n",
    "    pred_grades = df_pred['grades'].values.reshape(int(df_pred.shape[0] / k), k)\n",
    "\n",
    "    discount_vec = [1/np.log2(i+2) for i in range(k)]\n",
    "\n",
    "    # Calculate NDCG\n",
    "    NDCG = (pred_grades @ discount_vec).sum() / (ideal_grades @ discount_vec).sum()\n",
    "\n",
    "    return NDCG\n",
    "\n",
    "X_train, X_test, y_train, y_test, test_ideal = train_test_split(df_1, 'grades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RF\n",
      "Training XGB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m y_train_xgb[y_train \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     27\u001b[0m xgb_model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(objective\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmulti:softprob\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m xgb_model\u001b[39m.\u001b[39;49mfit(X_train, y_train_xgb)\n\u001b[0;32m     30\u001b[0m pred_ideal_rf \u001b[39m=\u001b[39m constructs_predictions(rf, X_test, ideal_df\u001b[39m=\u001b[39mtest_ideal)\n\u001b[0;32m     31\u001b[0m pred_xgb \u001b[39m=\u001b[39m constructs_predictions(xgb_model, X_test, ideal_df\u001b[39m=\u001b[39mtest_ideal)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1491\u001b[0m     params,\n\u001b[0;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1502\u001b[0m )\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print('Training RF')\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "print('Training XGB')\n",
    "import xgboost as xgb\n",
    "y_train_xgb = y_train.astype(int)\n",
    "y_train_xgb[y_train == 5] = 2\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(X_train, y_train_xgb)\n",
    "\n",
    "pred_ideal_rf = constructs_predictions(rf, X_test, ideal_df=test_ideal)\n",
    "pred_xgb = constructs_predictions(xgb_model, X_test, ideal_df=test_ideal)\n",
    "pred_random = construct_pred_ideal(X_test, test_ideal, np.random.rand(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 13:56:31,830]\u001b[0m A new study created in memory with name: no-name-3a7cbff6-7ed5-4fc1-8c20-9778f5cce14a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 13:58:02,635]\u001b[0m Trial 0 finished with value: 0.3422170675116014 and parameters: {'n_estimators': 218, 'max_depth': 10, 'learning_rate': 0.002795642578981349, 'subsample': 0.8932459525721343, 'colsample_bytree': 0.6546014752508442, 'gamma': 0.4545479889258107, 'reg_alpha': 0.0006735472057143736, 'reg_lambda': 0.05659086785788689}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 13:58:34,110]\u001b[0m Trial 1 finished with value: 0.3296238751532763 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.00020205115375924383, 'subsample': 0.6995347755906247, 'colsample_bytree': 0.9885228465832642, 'gamma': 0.19381601429279216, 'reg_alpha': 0.03803815623242628, 'reg_lambda': 0.00015357257740569215}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 13:59:37,760]\u001b[0m Trial 2 finished with value: 0.3368665578611753 and parameters: {'n_estimators': 472, 'max_depth': 4, 'learning_rate': 0.004549507912707027, 'subsample': 0.9923851580887791, 'colsample_bytree': 0.6814279943069872, 'gamma': 0.7401357393941124, 'reg_alpha': 0.0002258603906050948, 'reg_lambda': 0.028653594053630608}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:01:29,664]\u001b[0m Trial 3 finished with value: 0.339781517888877 and parameters: {'n_estimators': 306, 'max_depth': 6, 'learning_rate': 0.060275684993274646, 'subsample': 0.620320331182772, 'colsample_bytree': 0.9464989061090534, 'gamma': 0.3525375597606377, 'reg_alpha': 0.0003216130966291681, 'reg_lambda': 0.0005114090643305632}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:03:28,696]\u001b[0m Trial 4 finished with value: 0.3496082715804649 and parameters: {'n_estimators': 429, 'max_depth': 5, 'learning_rate': 0.06142220536965048, 'subsample': 0.6712997719996967, 'colsample_bytree': 0.8271779419344812, 'gamma': 0.7969399896200798, 'reg_alpha': 0.000677426646577888, 'reg_lambda': 0.03700082394822008}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:05:12,196]\u001b[0m Trial 5 finished with value: 0.3384792262060793 and parameters: {'n_estimators': 255, 'max_depth': 7, 'learning_rate': 0.04445704548420475, 'subsample': 0.5764517066858506, 'colsample_bytree': 0.8572909403044449, 'gamma': 0.26447303148260715, 'reg_alpha': 0.014856269301417238, 'reg_lambda': 0.06756544690765487}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:07:47,778]\u001b[0m Trial 6 finished with value: 0.3288661873274956 and parameters: {'n_estimators': 312, 'max_depth': 10, 'learning_rate': 0.06361043068846312, 'subsample': 0.614109694485647, 'colsample_bytree': 0.690990627225202, 'gamma': 0.6320192081820498, 'reg_alpha': 0.00021742258214232484, 'reg_lambda': 0.0005896239122363013}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:08:27,834]\u001b[0m Trial 7 finished with value: 0.34384549938446224 and parameters: {'n_estimators': 69, 'max_depth': 8, 'learning_rate': 0.0010117902047042774, 'subsample': 0.5509143251305197, 'colsample_bytree': 0.8569236855819127, 'gamma': 0.971456658004933, 'reg_alpha': 0.004542345369774203, 'reg_lambda': 0.003093509800346809}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:10:40,908]\u001b[0m Trial 8 finished with value: 0.34011673137777976 and parameters: {'n_estimators': 452, 'max_depth': 7, 'learning_rate': 0.0011321008620682482, 'subsample': 0.8295478463576602, 'colsample_bytree': 0.671414737192363, 'gamma': 0.7305115721105879, 'reg_alpha': 0.00012385564006791645, 'reg_lambda': 0.0002558991665383762}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:12:07,736]\u001b[0m Trial 9 finished with value: 0.3424228910661798 and parameters: {'n_estimators': 269, 'max_depth': 8, 'learning_rate': 0.00037359210176421875, 'subsample': 0.8060751589443202, 'colsample_bytree': 0.5510785207522584, 'gamma': 0.7526724292155883, 'reg_alpha': 0.0009308042088312982, 'reg_lambda': 0.00016796739944054614}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:12:55,928]\u001b[0m Trial 10 finished with value: 0.3442294127671065 and parameters: {'n_estimators': 386, 'max_depth': 3, 'learning_rate': 0.013364142140460148, 'subsample': 0.708724261611066, 'colsample_bytree': 0.7896130232357127, 'gamma': 0.05618920251021964, 'reg_alpha': 0.0015431363571254905, 'reg_lambda': 0.014196822762253699}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:13:47,232]\u001b[0m Trial 11 finished with value: 0.3560830490052606 and parameters: {'n_estimators': 392, 'max_depth': 3, 'learning_rate': 0.018998420243927058, 'subsample': 0.7068269457210393, 'colsample_bytree': 0.7846266947658518, 'gamma': 0.05287718678884501, 'reg_alpha': 0.0022645116016606925, 'reg_lambda': 0.013744086612321477}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:14:39,802]\u001b[0m Trial 12 finished with value: 0.3543543071898208 and parameters: {'n_estimators': 387, 'max_depth': 3, 'learning_rate': 0.018756027574930046, 'subsample': 0.6712932319218762, 'colsample_bytree': 0.780370594379618, 'gamma': 0.5142230603254847, 'reg_alpha': 0.004081559049808262, 'reg_lambda': 0.009443211407634506}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:15:30,405]\u001b[0m Trial 13 finished with value: 0.3516628290995864 and parameters: {'n_estimators': 361, 'max_depth': 3, 'learning_rate': 0.015102319848196757, 'subsample': 0.5014584532543078, 'colsample_bytree': 0.7617930521271803, 'gamma': 0.010571810108823965, 'reg_alpha': 0.004453410464019551, 'reg_lambda': 0.009540155317686446}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:16:36,573]\u001b[0m Trial 14 finished with value: 0.3553393333527243 and parameters: {'n_estimators': 396, 'max_depth': 4, 'learning_rate': 0.01648798679985499, 'subsample': 0.7400765255992919, 'colsample_bytree': 0.7472726903550169, 'gamma': 0.47012405874481084, 'reg_alpha': 0.002494784409867919, 'reg_lambda': 0.005039066603505889}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:17:07,310]\u001b[0m Trial 15 finished with value: 0.33721518793193683 and parameters: {'n_estimators': 194, 'max_depth': 4, 'learning_rate': 0.00876749486753917, 'subsample': 0.7587969640800073, 'colsample_bytree': 0.7225094152765875, 'gamma': 0.20481708761514125, 'reg_alpha': 0.0023349612169283715, 'reg_lambda': 0.0033495501384705265}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:18:12,175]\u001b[0m Trial 16 finished with value: 0.3586960449767132 and parameters: {'n_estimators': 489, 'max_depth': 4, 'learning_rate': 0.027855876474626316, 'subsample': 0.7527275830005006, 'colsample_bytree': 0.6115010002948956, 'gamma': 0.1062913910208294, 'reg_alpha': 0.011119124655306968, 'reg_lambda': 0.09892315408249078}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:19:33,635]\u001b[0m Trial 17 finished with value: 0.3531469396569031 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.027832715612830964, 'subsample': 0.7777013015138864, 'colsample_bytree': 0.6041003878041254, 'gamma': 0.0997557254325905, 'reg_alpha': 0.016012295331838736, 'reg_lambda': 0.070444644128135}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:20:35,604]\u001b[0m Trial 18 finished with value: 0.35224771448175324 and parameters: {'n_estimators': 339, 'max_depth': 6, 'learning_rate': 0.027987411838695936, 'subsample': 0.861869338388761, 'colsample_bytree': 0.5065642665059094, 'gamma': 0.11492715330320435, 'reg_alpha': 0.09182530901018138, 'reg_lambda': 0.08885290572015923}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:21:40,752]\u001b[0m Trial 19 finished with value: 0.35291651561050097 and parameters: {'n_estimators': 430, 'max_depth': 4, 'learning_rate': 0.09529096995868931, 'subsample': 0.7375071931614383, 'colsample_bytree': 0.6244981709223065, 'gamma': 0.03240613404282796, 'reg_alpha': 0.0065337960411954756, 'reg_lambda': 0.02198876587004922}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [0 1 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m     42\u001b[0m xgb_model_optimized \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(objective\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmulti:softprob\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_params)\n\u001b[1;32m---> 43\u001b[0m xgb_model_optimized\u001b[39m.\u001b[39;49mfit(X_train, y_train\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m))\n\u001b[0;32m     45\u001b[0m \u001b[39m# Evaluate the optimized model\u001b[39;00m\n\u001b[0;32m     46\u001b[0m pred_xgb_optimized \u001b[39m=\u001b[39m constructs_predictions(xgb_model_optimized, X_test, ideal_df\u001b[39m=\u001b[39mtest_ideal)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1440\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1435\u001b[0m     expected_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[0;32m   1436\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1437\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1438\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1439\u001b[0m ):\n\u001b[1;32m-> 1440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1442\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1443\u001b[0m     )\n\u001b[0;32m   1445\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [0 1 5]"
     ]
    }
   ],
   "source": [
    "# Optimize XGB with optuna\n",
    "import optuna\n",
    "from functools import partial\n",
    "\n",
    "def objective(trial, X_train, y_train, X_test, test_ideal):\n",
    "    y_train_xgb = y_train.astype(int)\n",
    "    y_train_xgb[y_train == 5] = 2\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-4, 1e-1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-4, 1e-1, log=True),\n",
    "    }\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(**params)\n",
    "    xgb_model.fit(X_train, y_train_xgb)\n",
    "\n",
    "    pred_xgb = constructs_predictions(xgb_model, X_test, ideal_df=test_ideal)\n",
    "    ndcg = calc_NDCG(test_ideal, pred_xgb)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "print(\"Training XGB\")\n",
    "# Assuming you have defined X_train, y_train, X_test, and test_ideal before this point.\n",
    "\n",
    "# Wrap the objective function with the input data\n",
    "objective_with_data = partial(objective, X_train=X_train, y_train=y_train, X_test=X_test, test_ideal=test_ideal)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_with_data, n_trials=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Optimized: 0.3586960449767132\n"
     ]
    }
   ],
   "source": [
    "y_train_xgb = y_train.astype(int)\n",
    "y_train_xgb[y_train == 5] = 2\n",
    "\n",
    "# Get the best hyperparameters and train the final model\n",
    "best_params = study.best_params\n",
    "xgb_model_optimized = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42, **best_params)\n",
    "xgb_model_optimized.fit(X_train, y_train_xgb)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "pred_xgb_optimized = constructs_predictions(xgb_model_optimized, X_test, ideal_df=test_ideal)\n",
    "pred_xgb_submission = constructs_predictions(xgb_model_optimized, df_t)\n",
    "print(f\"XGB Optimized: {calc_NDCG(test_ideal, pred_xgb_optimized)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.28572611476380494\n",
      ",XGB: 0.3413833342709407,\n",
      "Random: 0.16416903670552785\n"
     ]
    }
   ],
   "source": [
    "print(f\"RF: {calc_NDCG(test_ideal, pred_ideal_rf)}\\n,XGB: {calc_NDCG(test_ideal, pred_xgb)},\\nRandom: {calc_NDCG(test_ideal, pred_random)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_submission.to_csv(config['PATH']['DATA_DIR'] + '/submission_RF.csv', index=False)\n",
    "pred_xgb_submission.to_csv(config['PATH']['DATA_DIR'] + '/submission_XGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>prop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>99484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>54937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>61934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>28181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>63894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959177</th>\n",
       "      <td>332787</td>\n",
       "      <td>29018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959178</th>\n",
       "      <td>332787</td>\n",
       "      <td>32019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959181</th>\n",
       "      <td>332787</td>\n",
       "      <td>94437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959182</th>\n",
       "      <td>332787</td>\n",
       "      <td>99509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959180</th>\n",
       "      <td>332787</td>\n",
       "      <td>35240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4959183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id  prop_id\n",
       "23             1    99484\n",
       "9              1    54937\n",
       "12             1    61934\n",
       "5              1    28181\n",
       "13             1    63894\n",
       "...          ...      ...\n",
       "4959177   332787    29018\n",
       "4959178   332787    32019\n",
       "4959181   332787    94437\n",
       "4959182   332787    99509\n",
       "4959180   332787    35240\n",
       "\n",
       "[4959183 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_xgb_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "870a2fdea9c478e83829f6dfe3253b795de45ac3a80f5a95ea9a0c5415ff5b84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
