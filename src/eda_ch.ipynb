{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "from helpers.helper_functions import *\n",
    "from helpers.helper_classes import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('src/config.ini')\n",
    "os.chdir(config['PATH']['ROOT_DIR'])\n",
    "\n",
    "# # Load data\n",
    "df = pd.read_parquet(config['PATH']['INT_DIR'] + '/training_set_preprocessed_nodrop.parquet', engine = 'fastparquet')\n",
    "df_test = pd.read_parquet(config['PATH']['INT_DIR'] + '/test_set_preprocessed_nodrop.parquet', engine = 'fastparquet')\n",
    "df_mini = df[df['srch_id'] < 10000]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's ndcg@5: 0.311332\n",
      "[2]\ttraining's ndcg@5: 0.340176\n",
      "[3]\ttraining's ndcg@5: 0.353938\n",
      "[4]\ttraining's ndcg@5: 0.364675\n",
      "[5]\ttraining's ndcg@5: 0.369557\n",
      "[6]\ttraining's ndcg@5: 0.374246\n",
      "[7]\ttraining's ndcg@5: 0.379012\n",
      "[8]\ttraining's ndcg@5: 0.380643\n",
      "[9]\ttraining's ndcg@5: 0.382195\n",
      "[10]\ttraining's ndcg@5: 0.382835\n",
      "[11]\ttraining's ndcg@5: 0.383356\n",
      "[12]\ttraining's ndcg@5: 0.383611\n",
      "[13]\ttraining's ndcg@5: 0.384379\n",
      "[14]\ttraining's ndcg@5: 0.385761\n",
      "[15]\ttraining's ndcg@5: 0.386084\n",
      "[16]\ttraining's ndcg@5: 0.38726\n",
      "[17]\ttraining's ndcg@5: 0.388015\n",
      "[18]\ttraining's ndcg@5: 0.388602\n",
      "[19]\ttraining's ndcg@5: 0.388948\n",
      "[20]\ttraining's ndcg@5: 0.389187\n",
      "[21]\ttraining's ndcg@5: 0.389524\n",
      "[22]\ttraining's ndcg@5: 0.389945\n",
      "[23]\ttraining's ndcg@5: 0.390357\n",
      "[24]\ttraining's ndcg@5: 0.390422\n",
      "[25]\ttraining's ndcg@5: 0.390725\n",
      "[26]\ttraining's ndcg@5: 0.390994\n",
      "[27]\ttraining's ndcg@5: 0.391589\n",
      "[28]\ttraining's ndcg@5: 0.391603\n",
      "[29]\ttraining's ndcg@5: 0.392097\n",
      "[30]\ttraining's ndcg@5: 0.392066\n",
      "[31]\ttraining's ndcg@5: 0.392094\n",
      "[32]\ttraining's ndcg@5: 0.392428\n",
      "[33]\ttraining's ndcg@5: 0.392314\n",
      "[34]\ttraining's ndcg@5: 0.392497\n",
      "[35]\ttraining's ndcg@5: 0.392696\n",
      "[36]\ttraining's ndcg@5: 0.393315\n",
      "[37]\ttraining's ndcg@5: 0.393497\n",
      "[38]\ttraining's ndcg@5: 0.393469\n",
      "[39]\ttraining's ndcg@5: 0.393608\n",
      "[40]\ttraining's ndcg@5: 0.393706\n",
      "[41]\ttraining's ndcg@5: 0.394032\n",
      "[42]\ttraining's ndcg@5: 0.394294\n",
      "[43]\ttraining's ndcg@5: 0.394471\n",
      "[44]\ttraining's ndcg@5: 0.394486\n",
      "[45]\ttraining's ndcg@5: 0.394375\n",
      "[46]\ttraining's ndcg@5: 0.39469\n",
      "[47]\ttraining's ndcg@5: 0.394744\n",
      "[48]\ttraining's ndcg@5: 0.395043\n",
      "[49]\ttraining's ndcg@5: 0.395376\n",
      "[50]\ttraining's ndcg@5: 0.395507\n",
      "[51]\ttraining's ndcg@5: 0.395722\n",
      "[52]\ttraining's ndcg@5: 0.395973\n",
      "[53]\ttraining's ndcg@5: 0.396118\n",
      "[54]\ttraining's ndcg@5: 0.396265\n",
      "[55]\ttraining's ndcg@5: 0.396153\n",
      "[56]\ttraining's ndcg@5: 0.396643\n",
      "[57]\ttraining's ndcg@5: 0.396756\n",
      "[58]\ttraining's ndcg@5: 0.396915\n",
      "[59]\ttraining's ndcg@5: 0.396954\n",
      "[60]\ttraining's ndcg@5: 0.397086\n",
      "[61]\ttraining's ndcg@5: 0.397291\n",
      "[62]\ttraining's ndcg@5: 0.397659\n",
      "[63]\ttraining's ndcg@5: 0.397778\n",
      "[64]\ttraining's ndcg@5: 0.397897\n",
      "[65]\ttraining's ndcg@5: 0.398075\n",
      "[66]\ttraining's ndcg@5: 0.398029\n",
      "[67]\ttraining's ndcg@5: 0.398297\n",
      "[68]\ttraining's ndcg@5: 0.398507\n",
      "[69]\ttraining's ndcg@5: 0.398793\n",
      "[70]\ttraining's ndcg@5: 0.398986\n",
      "[71]\ttraining's ndcg@5: 0.39901\n",
      "[72]\ttraining's ndcg@5: 0.399085\n",
      "[73]\ttraining's ndcg@5: 0.399204\n",
      "[74]\ttraining's ndcg@5: 0.399375\n",
      "[75]\ttraining's ndcg@5: 0.399591\n",
      "[76]\ttraining's ndcg@5: 0.399837\n",
      "[77]\ttraining's ndcg@5: 0.400118\n",
      "[78]\ttraining's ndcg@5: 0.400206\n",
      "[79]\ttraining's ndcg@5: 0.40031\n",
      "[80]\ttraining's ndcg@5: 0.400515\n",
      "[81]\ttraining's ndcg@5: 0.40061\n",
      "[82]\ttraining's ndcg@5: 0.400748\n",
      "[83]\ttraining's ndcg@5: 0.400908\n",
      "[84]\ttraining's ndcg@5: 0.400997\n",
      "[85]\ttraining's ndcg@5: 0.401155\n",
      "[86]\ttraining's ndcg@5: 0.401357\n",
      "[87]\ttraining's ndcg@5: 0.401461\n",
      "[88]\ttraining's ndcg@5: 0.401522\n",
      "[89]\ttraining's ndcg@5: 0.401647\n",
      "[90]\ttraining's ndcg@5: 0.401619\n",
      "[91]\ttraining's ndcg@5: 0.401816\n",
      "[92]\ttraining's ndcg@5: 0.401777\n",
      "[93]\ttraining's ndcg@5: 0.401903\n",
      "[94]\ttraining's ndcg@5: 0.402044\n",
      "[95]\ttraining's ndcg@5: 0.402128\n",
      "[96]\ttraining's ndcg@5: 0.402257\n",
      "[97]\ttraining's ndcg@5: 0.402388\n",
      "[98]\ttraining's ndcg@5: 0.402445\n",
      "[99]\ttraining's ndcg@5: 0.402441\n",
      "[100]\ttraining's ndcg@5: 0.402686\n",
      "[101]\ttraining's ndcg@5: 0.402919\n",
      "[102]\ttraining's ndcg@5: 0.402955\n",
      "[103]\ttraining's ndcg@5: 0.403175\n",
      "[104]\ttraining's ndcg@5: 0.403103\n",
      "[105]\ttraining's ndcg@5: 0.403319\n",
      "[106]\ttraining's ndcg@5: 0.403561\n",
      "[107]\ttraining's ndcg@5: 0.403705\n",
      "[108]\ttraining's ndcg@5: 0.403843\n",
      "[109]\ttraining's ndcg@5: 0.403858\n",
      "[110]\ttraining's ndcg@5: 0.403939\n",
      "[111]\ttraining's ndcg@5: 0.404173\n",
      "[112]\ttraining's ndcg@5: 0.404484\n",
      "[113]\ttraining's ndcg@5: 0.404642\n",
      "[114]\ttraining's ndcg@5: 0.404652\n",
      "[115]\ttraining's ndcg@5: 0.404831\n",
      "[116]\ttraining's ndcg@5: 0.404863\n",
      "[117]\ttraining's ndcg@5: 0.405077\n",
      "[118]\ttraining's ndcg@5: 0.405251\n",
      "[119]\ttraining's ndcg@5: 0.40534\n",
      "[120]\ttraining's ndcg@5: 0.405371\n",
      "[121]\ttraining's ndcg@5: 0.405585\n",
      "[122]\ttraining's ndcg@5: 0.40564\n",
      "[123]\ttraining's ndcg@5: 0.40576\n",
      "[124]\ttraining's ndcg@5: 0.406074\n",
      "[125]\ttraining's ndcg@5: 0.406052\n",
      "[126]\ttraining's ndcg@5: 0.406231\n",
      "[127]\ttraining's ndcg@5: 0.406349\n",
      "[128]\ttraining's ndcg@5: 0.406464\n",
      "[129]\ttraining's ndcg@5: 0.406538\n",
      "[130]\ttraining's ndcg@5: 0.406533\n",
      "[131]\ttraining's ndcg@5: 0.406672\n",
      "[132]\ttraining's ndcg@5: 0.406856\n",
      "[133]\ttraining's ndcg@5: 0.407074\n",
      "[134]\ttraining's ndcg@5: 0.407032\n",
      "[135]\ttraining's ndcg@5: 0.407044\n",
      "[136]\ttraining's ndcg@5: 0.407121\n",
      "[137]\ttraining's ndcg@5: 0.407275\n",
      "[138]\ttraining's ndcg@5: 0.407291\n",
      "[139]\ttraining's ndcg@5: 0.407387\n",
      "[140]\ttraining's ndcg@5: 0.40747\n",
      "[141]\ttraining's ndcg@5: 0.407568\n",
      "[142]\ttraining's ndcg@5: 0.407723\n",
      "[143]\ttraining's ndcg@5: 0.407794\n",
      "[144]\ttraining's ndcg@5: 0.407923\n",
      "[145]\ttraining's ndcg@5: 0.408003\n",
      "[146]\ttraining's ndcg@5: 0.408084\n",
      "[147]\ttraining's ndcg@5: 0.408176\n",
      "[148]\ttraining's ndcg@5: 0.408408\n",
      "[149]\ttraining's ndcg@5: 0.408467\n",
      "[150]\ttraining's ndcg@5: 0.408574\n",
      "[151]\ttraining's ndcg@5: 0.40871\n",
      "[152]\ttraining's ndcg@5: 0.408802\n",
      "[153]\ttraining's ndcg@5: 0.408969\n",
      "[154]\ttraining's ndcg@5: 0.409167\n",
      "[155]\ttraining's ndcg@5: 0.409139\n",
      "[156]\ttraining's ndcg@5: 0.409339\n",
      "[157]\ttraining's ndcg@5: 0.409407\n",
      "[158]\ttraining's ndcg@5: 0.409551\n",
      "[159]\ttraining's ndcg@5: 0.409657\n",
      "[160]\ttraining's ndcg@5: 0.409823\n",
      "[161]\ttraining's ndcg@5: 0.409819\n",
      "[162]\ttraining's ndcg@5: 0.410011\n",
      "[163]\ttraining's ndcg@5: 0.41004\n",
      "[164]\ttraining's ndcg@5: 0.410143\n",
      "[165]\ttraining's ndcg@5: 0.410302\n",
      "[166]\ttraining's ndcg@5: 0.410471\n",
      "[167]\ttraining's ndcg@5: 0.410606\n",
      "[168]\ttraining's ndcg@5: 0.410589\n",
      "[169]\ttraining's ndcg@5: 0.410673\n",
      "[170]\ttraining's ndcg@5: 0.410802\n",
      "[171]\ttraining's ndcg@5: 0.410928\n",
      "[172]\ttraining's ndcg@5: 0.411065\n",
      "[173]\ttraining's ndcg@5: 0.411305\n",
      "[174]\ttraining's ndcg@5: 0.411355\n",
      "[175]\ttraining's ndcg@5: 0.411423\n",
      "[176]\ttraining's ndcg@5: 0.411605\n",
      "[177]\ttraining's ndcg@5: 0.411681\n",
      "[178]\ttraining's ndcg@5: 0.411802\n",
      "[179]\ttraining's ndcg@5: 0.411889\n",
      "[180]\ttraining's ndcg@5: 0.412085\n",
      "[181]\ttraining's ndcg@5: 0.412118\n",
      "[182]\ttraining's ndcg@5: 0.412245\n",
      "[183]\ttraining's ndcg@5: 0.412292\n",
      "[184]\ttraining's ndcg@5: 0.412352\n",
      "[185]\ttraining's ndcg@5: 0.412511\n",
      "[186]\ttraining's ndcg@5: 0.412634\n",
      "[187]\ttraining's ndcg@5: 0.412829\n",
      "[188]\ttraining's ndcg@5: 0.412782\n",
      "[189]\ttraining's ndcg@5: 0.412808\n",
      "[190]\ttraining's ndcg@5: 0.412975\n",
      "[191]\ttraining's ndcg@5: 0.413137\n",
      "[192]\ttraining's ndcg@5: 0.413319\n",
      "[193]\ttraining's ndcg@5: 0.413406\n",
      "[194]\ttraining's ndcg@5: 0.413524\n",
      "[195]\ttraining's ndcg@5: 0.413668\n",
      "[196]\ttraining's ndcg@5: 0.41371\n",
      "[197]\ttraining's ndcg@5: 0.413676\n",
      "[198]\ttraining's ndcg@5: 0.413784\n",
      "[199]\ttraining's ndcg@5: 0.413932\n",
      "[200]\ttraining's ndcg@5: 0.414022\n",
      "[201]\ttraining's ndcg@5: 0.414045\n",
      "[202]\ttraining's ndcg@5: 0.414123\n",
      "[203]\ttraining's ndcg@5: 0.414261\n",
      "[204]\ttraining's ndcg@5: 0.414381\n",
      "[205]\ttraining's ndcg@5: 0.414452\n",
      "[206]\ttraining's ndcg@5: 0.41453\n",
      "[207]\ttraining's ndcg@5: 0.4145\n",
      "[208]\ttraining's ndcg@5: 0.414609\n",
      "[209]\ttraining's ndcg@5: 0.414694\n",
      "[210]\ttraining's ndcg@5: 0.414791\n",
      "[211]\ttraining's ndcg@5: 0.414905\n",
      "[212]\ttraining's ndcg@5: 0.415037\n",
      "[213]\ttraining's ndcg@5: 0.415201\n",
      "[214]\ttraining's ndcg@5: 0.415284\n",
      "[215]\ttraining's ndcg@5: 0.41541\n",
      "[216]\ttraining's ndcg@5: 0.415432\n",
      "[217]\ttraining's ndcg@5: 0.415652\n",
      "[218]\ttraining's ndcg@5: 0.415704\n",
      "[219]\ttraining's ndcg@5: 0.415704\n",
      "[220]\ttraining's ndcg@5: 0.415771\n",
      "[221]\ttraining's ndcg@5: 0.415861\n",
      "[222]\ttraining's ndcg@5: 0.415977\n",
      "[223]\ttraining's ndcg@5: 0.415916\n",
      "[224]\ttraining's ndcg@5: 0.416151\n",
      "[225]\ttraining's ndcg@5: 0.416269\n",
      "[226]\ttraining's ndcg@5: 0.416287\n",
      "[227]\ttraining's ndcg@5: 0.416314\n",
      "[228]\ttraining's ndcg@5: 0.416415\n",
      "[229]\ttraining's ndcg@5: 0.416451\n",
      "[230]\ttraining's ndcg@5: 0.416552\n",
      "[231]\ttraining's ndcg@5: 0.416625\n",
      "[232]\ttraining's ndcg@5: 0.416649\n",
      "[233]\ttraining's ndcg@5: 0.416769\n",
      "[234]\ttraining's ndcg@5: 0.416873\n",
      "[235]\ttraining's ndcg@5: 0.417004\n",
      "[236]\ttraining's ndcg@5: 0.41713\n",
      "[237]\ttraining's ndcg@5: 0.417203\n",
      "[238]\ttraining's ndcg@5: 0.417354\n",
      "[239]\ttraining's ndcg@5: 0.417411\n",
      "[240]\ttraining's ndcg@5: 0.417573\n",
      "[241]\ttraining's ndcg@5: 0.41768\n",
      "[242]\ttraining's ndcg@5: 0.417739\n",
      "[243]\ttraining's ndcg@5: 0.417893\n",
      "[244]\ttraining's ndcg@5: 0.417951\n",
      "[245]\ttraining's ndcg@5: 0.418014\n",
      "[246]\ttraining's ndcg@5: 0.418134\n",
      "[247]\ttraining's ndcg@5: 0.418198\n",
      "[248]\ttraining's ndcg@5: 0.418321\n",
      "[249]\ttraining's ndcg@5: 0.418395\n",
      "[250]\ttraining's ndcg@5: 0.418457\n",
      "[251]\ttraining's ndcg@5: 0.418503\n",
      "[252]\ttraining's ndcg@5: 0.418525\n",
      "[253]\ttraining's ndcg@5: 0.418648\n",
      "[254]\ttraining's ndcg@5: 0.418605\n",
      "[255]\ttraining's ndcg@5: 0.418772\n",
      "[256]\ttraining's ndcg@5: 0.418805\n",
      "[257]\ttraining's ndcg@5: 0.418794\n",
      "[258]\ttraining's ndcg@5: 0.418996\n",
      "[259]\ttraining's ndcg@5: 0.419126\n",
      "[260]\ttraining's ndcg@5: 0.419182\n",
      "[261]\ttraining's ndcg@5: 0.419288\n",
      "[262]\ttraining's ndcg@5: 0.419451\n",
      "[263]\ttraining's ndcg@5: 0.419561\n",
      "[264]\ttraining's ndcg@5: 0.419637\n",
      "[265]\ttraining's ndcg@5: 0.41977\n",
      "[266]\ttraining's ndcg@5: 0.419792\n",
      "[267]\ttraining's ndcg@5: 0.419944\n",
      "[268]\ttraining's ndcg@5: 0.420033\n",
      "[269]\ttraining's ndcg@5: 0.420133\n",
      "[270]\ttraining's ndcg@5: 0.420227\n",
      "[271]\ttraining's ndcg@5: 0.420312\n",
      "[272]\ttraining's ndcg@5: 0.420347\n",
      "[273]\ttraining's ndcg@5: 0.420366\n",
      "[274]\ttraining's ndcg@5: 0.420545\n",
      "[275]\ttraining's ndcg@5: 0.420711\n",
      "[276]\ttraining's ndcg@5: 0.420761\n",
      "[277]\ttraining's ndcg@5: 0.420862\n",
      "[278]\ttraining's ndcg@5: 0.421067\n",
      "[279]\ttraining's ndcg@5: 0.421181\n",
      "[280]\ttraining's ndcg@5: 0.421234\n",
      "[281]\ttraining's ndcg@5: 0.42129\n",
      "[282]\ttraining's ndcg@5: 0.421334\n",
      "[283]\ttraining's ndcg@5: 0.421335\n",
      "[284]\ttraining's ndcg@5: 0.42148\n",
      "[285]\ttraining's ndcg@5: 0.421552\n",
      "[286]\ttraining's ndcg@5: 0.421683\n",
      "[287]\ttraining's ndcg@5: 0.421719\n",
      "[288]\ttraining's ndcg@5: 0.421886\n",
      "[289]\ttraining's ndcg@5: 0.421957\n",
      "[290]\ttraining's ndcg@5: 0.422\n",
      "[291]\ttraining's ndcg@5: 0.422048\n",
      "[292]\ttraining's ndcg@5: 0.422204\n",
      "[293]\ttraining's ndcg@5: 0.422264\n",
      "[294]\ttraining's ndcg@5: 0.422409\n",
      "[295]\ttraining's ndcg@5: 0.42248\n",
      "[296]\ttraining's ndcg@5: 0.422574\n",
      "[297]\ttraining's ndcg@5: 0.422606\n",
      "[298]\ttraining's ndcg@5: 0.422611\n",
      "[299]\ttraining's ndcg@5: 0.422626\n",
      "[300]\ttraining's ndcg@5: 0.422699\n",
      "[301]\ttraining's ndcg@5: 0.422734\n",
      "[302]\ttraining's ndcg@5: 0.422865\n",
      "[303]\ttraining's ndcg@5: 0.423011\n",
      "[304]\ttraining's ndcg@5: 0.423092\n",
      "[305]\ttraining's ndcg@5: 0.423247\n",
      "[306]\ttraining's ndcg@5: 0.423292\n",
      "[307]\ttraining's ndcg@5: 0.423304\n",
      "[308]\ttraining's ndcg@5: 0.423421\n",
      "[309]\ttraining's ndcg@5: 0.423484\n",
      "[310]\ttraining's ndcg@5: 0.423586\n",
      "[311]\ttraining's ndcg@5: 0.423635\n",
      "[312]\ttraining's ndcg@5: 0.423853\n",
      "[313]\ttraining's ndcg@5: 0.423929\n",
      "[314]\ttraining's ndcg@5: 0.423973\n",
      "[315]\ttraining's ndcg@5: 0.424115\n",
      "[316]\ttraining's ndcg@5: 0.424149\n",
      "[317]\ttraining's ndcg@5: 0.424272\n",
      "[318]\ttraining's ndcg@5: 0.424399\n",
      "[319]\ttraining's ndcg@5: 0.424438\n",
      "[320]\ttraining's ndcg@5: 0.424409\n",
      "[321]\ttraining's ndcg@5: 0.424548\n",
      "[322]\ttraining's ndcg@5: 0.424654\n",
      "[323]\ttraining's ndcg@5: 0.424704\n",
      "[324]\ttraining's ndcg@5: 0.424821\n",
      "[325]\ttraining's ndcg@5: 0.424939\n",
      "[326]\ttraining's ndcg@5: 0.425073\n",
      "[327]\ttraining's ndcg@5: 0.425145\n",
      "[328]\ttraining's ndcg@5: 0.425277\n",
      "[329]\ttraining's ndcg@5: 0.425343\n",
      "[330]\ttraining's ndcg@5: 0.425407\n",
      "[331]\ttraining's ndcg@5: 0.425507\n",
      "[332]\ttraining's ndcg@5: 0.425582\n",
      "[333]\ttraining's ndcg@5: 0.425684\n",
      "[334]\ttraining's ndcg@5: 0.425776\n",
      "[335]\ttraining's ndcg@5: 0.425852\n",
      "[336]\ttraining's ndcg@5: 0.425961\n",
      "[337]\ttraining's ndcg@5: 0.426053\n",
      "[338]\ttraining's ndcg@5: 0.426119\n",
      "[339]\ttraining's ndcg@5: 0.42617\n",
      "[340]\ttraining's ndcg@5: 0.426236\n",
      "[341]\ttraining's ndcg@5: 0.42639\n",
      "[342]\ttraining's ndcg@5: 0.426478\n",
      "[343]\ttraining's ndcg@5: 0.426514\n",
      "[344]\ttraining's ndcg@5: 0.426536\n",
      "[345]\ttraining's ndcg@5: 0.42656\n",
      "[346]\ttraining's ndcg@5: 0.4266\n",
      "[347]\ttraining's ndcg@5: 0.426706\n",
      "[348]\ttraining's ndcg@5: 0.426885\n",
      "[349]\ttraining's ndcg@5: 0.426934\n",
      "[350]\ttraining's ndcg@5: 0.427024\n",
      "[351]\ttraining's ndcg@5: 0.427161\n",
      "[352]\ttraining's ndcg@5: 0.427088\n",
      "[353]\ttraining's ndcg@5: 0.427183\n",
      "[354]\ttraining's ndcg@5: 0.427246\n",
      "[355]\ttraining's ndcg@5: 0.427319\n",
      "[356]\ttraining's ndcg@5: 0.427434\n",
      "[357]\ttraining's ndcg@5: 0.427468\n",
      "[358]\ttraining's ndcg@5: 0.427472\n",
      "[359]\ttraining's ndcg@5: 0.427586\n",
      "[360]\ttraining's ndcg@5: 0.42765\n",
      "[361]\ttraining's ndcg@5: 0.427712\n",
      "[362]\ttraining's ndcg@5: 0.427762\n",
      "[363]\ttraining's ndcg@5: 0.427811\n",
      "[364]\ttraining's ndcg@5: 0.427877\n",
      "[365]\ttraining's ndcg@5: 0.427942\n",
      "[366]\ttraining's ndcg@5: 0.428018\n",
      "[367]\ttraining's ndcg@5: 0.428098\n",
      "[368]\ttraining's ndcg@5: 0.428125\n",
      "[369]\ttraining's ndcg@5: 0.42818\n",
      "[370]\ttraining's ndcg@5: 0.428254\n",
      "[371]\ttraining's ndcg@5: 0.428381\n",
      "[372]\ttraining's ndcg@5: 0.428476\n",
      "[373]\ttraining's ndcg@5: 0.428594\n",
      "[374]\ttraining's ndcg@5: 0.428633\n",
      "[375]\ttraining's ndcg@5: 0.428707\n",
      "[376]\ttraining's ndcg@5: 0.428776\n",
      "[377]\ttraining's ndcg@5: 0.428834\n",
      "[378]\ttraining's ndcg@5: 0.428873\n",
      "[379]\ttraining's ndcg@5: 0.428948\n",
      "[380]\ttraining's ndcg@5: 0.429017\n",
      "[381]\ttraining's ndcg@5: 0.429115\n",
      "[382]\ttraining's ndcg@5: 0.42916\n",
      "[383]\ttraining's ndcg@5: 0.429156\n",
      "[384]\ttraining's ndcg@5: 0.429231\n",
      "[385]\ttraining's ndcg@5: 0.429315\n",
      "[386]\ttraining's ndcg@5: 0.429399\n",
      "[387]\ttraining's ndcg@5: 0.429455\n",
      "[388]\ttraining's ndcg@5: 0.4295\n",
      "[389]\ttraining's ndcg@5: 0.429567\n",
      "[390]\ttraining's ndcg@5: 0.429628\n",
      "[391]\ttraining's ndcg@5: 0.429682\n",
      "[392]\ttraining's ndcg@5: 0.429758\n",
      "[393]\ttraining's ndcg@5: 0.429823\n",
      "[394]\ttraining's ndcg@5: 0.429864\n",
      "[395]\ttraining's ndcg@5: 0.429928\n",
      "[396]\ttraining's ndcg@5: 0.430001\n",
      "[397]\ttraining's ndcg@5: 0.430124\n",
      "[398]\ttraining's ndcg@5: 0.430279\n",
      "[399]\ttraining's ndcg@5: 0.430377\n",
      "[400]\ttraining's ndcg@5: 0.430412\n",
      "[401]\ttraining's ndcg@5: 0.430493\n",
      "[402]\ttraining's ndcg@5: 0.430595\n",
      "[403]\ttraining's ndcg@5: 0.43062\n",
      "[404]\ttraining's ndcg@5: 0.430727\n",
      "[405]\ttraining's ndcg@5: 0.430825\n",
      "[406]\ttraining's ndcg@5: 0.430894\n",
      "[407]\ttraining's ndcg@5: 0.430906\n",
      "[408]\ttraining's ndcg@5: 0.431007\n",
      "[409]\ttraining's ndcg@5: 0.430966\n",
      "[410]\ttraining's ndcg@5: 0.431047\n",
      "[411]\ttraining's ndcg@5: 0.431168\n",
      "[412]\ttraining's ndcg@5: 0.431302\n",
      "[413]\ttraining's ndcg@5: 0.431446\n",
      "[414]\ttraining's ndcg@5: 0.431532\n",
      "[415]\ttraining's ndcg@5: 0.431635\n",
      "[416]\ttraining's ndcg@5: 0.431672\n",
      "[417]\ttraining's ndcg@5: 0.431773\n",
      "[418]\ttraining's ndcg@5: 0.431865\n",
      "[419]\ttraining's ndcg@5: 0.431935\n",
      "[420]\ttraining's ndcg@5: 0.431969\n",
      "[421]\ttraining's ndcg@5: 0.432049\n",
      "[422]\ttraining's ndcg@5: 0.432089\n",
      "[423]\ttraining's ndcg@5: 0.432085\n",
      "[424]\ttraining's ndcg@5: 0.432173\n",
      "[425]\ttraining's ndcg@5: 0.432285\n",
      "[426]\ttraining's ndcg@5: 0.432321\n",
      "[427]\ttraining's ndcg@5: 0.432452\n",
      "[428]\ttraining's ndcg@5: 0.432526\n",
      "[429]\ttraining's ndcg@5: 0.43267\n",
      "[430]\ttraining's ndcg@5: 0.432744\n",
      "[431]\ttraining's ndcg@5: 0.43278\n",
      "[432]\ttraining's ndcg@5: 0.432861\n",
      "[433]\ttraining's ndcg@5: 0.432927\n",
      "[434]\ttraining's ndcg@5: 0.432992\n",
      "[435]\ttraining's ndcg@5: 0.433058\n",
      "[436]\ttraining's ndcg@5: 0.433116\n",
      "[437]\ttraining's ndcg@5: 0.433187\n",
      "[438]\ttraining's ndcg@5: 0.433234\n",
      "[439]\ttraining's ndcg@5: 0.433331\n",
      "[440]\ttraining's ndcg@5: 0.433382\n",
      "[441]\ttraining's ndcg@5: 0.433406\n",
      "[442]\ttraining's ndcg@5: 0.43347\n",
      "[443]\ttraining's ndcg@5: 0.433567\n",
      "[444]\ttraining's ndcg@5: 0.43363\n",
      "[445]\ttraining's ndcg@5: 0.433695\n",
      "[446]\ttraining's ndcg@5: 0.433759\n",
      "[447]\ttraining's ndcg@5: 0.433818\n",
      "[448]\ttraining's ndcg@5: 0.433868\n",
      "[449]\ttraining's ndcg@5: 0.433938\n",
      "[450]\ttraining's ndcg@5: 0.433929\n",
      "[451]\ttraining's ndcg@5: 0.433964\n",
      "[452]\ttraining's ndcg@5: 0.433979\n",
      "[453]\ttraining's ndcg@5: 0.434055\n",
      "[454]\ttraining's ndcg@5: 0.434152\n",
      "[455]\ttraining's ndcg@5: 0.434213\n",
      "[456]\ttraining's ndcg@5: 0.434336\n",
      "[457]\ttraining's ndcg@5: 0.434428\n",
      "[458]\ttraining's ndcg@5: 0.434505\n",
      "[459]\ttraining's ndcg@5: 0.434583\n",
      "[460]\ttraining's ndcg@5: 0.434592\n",
      "[461]\ttraining's ndcg@5: 0.434659\n",
      "[462]\ttraining's ndcg@5: 0.434727\n",
      "[463]\ttraining's ndcg@5: 0.434797\n",
      "[464]\ttraining's ndcg@5: 0.434783\n",
      "[465]\ttraining's ndcg@5: 0.434914\n",
      "[466]\ttraining's ndcg@5: 0.435035\n",
      "[467]\ttraining's ndcg@5: 0.435113\n",
      "[468]\ttraining's ndcg@5: 0.435146\n",
      "[469]\ttraining's ndcg@5: 0.435216\n",
      "[470]\ttraining's ndcg@5: 0.43527\n",
      "[471]\ttraining's ndcg@5: 0.435324\n",
      "[472]\ttraining's ndcg@5: 0.435402\n",
      "[473]\ttraining's ndcg@5: 0.435424\n",
      "[474]\ttraining's ndcg@5: 0.435486\n",
      "[475]\ttraining's ndcg@5: 0.435546\n",
      "[476]\ttraining's ndcg@5: 0.435632\n",
      "[477]\ttraining's ndcg@5: 0.435681\n",
      "[478]\ttraining's ndcg@5: 0.435744\n",
      "[479]\ttraining's ndcg@5: 0.435788\n",
      "[480]\ttraining's ndcg@5: 0.43587\n",
      "[481]\ttraining's ndcg@5: 0.435913\n",
      "[482]\ttraining's ndcg@5: 0.435967\n",
      "[483]\ttraining's ndcg@5: 0.436025\n",
      "[484]\ttraining's ndcg@5: 0.43601\n",
      "[485]\ttraining's ndcg@5: 0.436076\n",
      "[486]\ttraining's ndcg@5: 0.436127\n",
      "[487]\ttraining's ndcg@5: 0.436158\n",
      "[488]\ttraining's ndcg@5: 0.436219\n",
      "[489]\ttraining's ndcg@5: 0.436278\n",
      "[490]\ttraining's ndcg@5: 0.436303\n",
      "[491]\ttraining's ndcg@5: 0.436325\n",
      "[492]\ttraining's ndcg@5: 0.436427\n",
      "[493]\ttraining's ndcg@5: 0.436503\n",
      "[494]\ttraining's ndcg@5: 0.436623\n",
      "[495]\ttraining's ndcg@5: 0.436678\n",
      "[496]\ttraining's ndcg@5: 0.436712\n",
      "[497]\ttraining's ndcg@5: 0.436802\n",
      "[498]\ttraining's ndcg@5: 0.436889\n",
      "[499]\ttraining's ndcg@5: 0.436975\n",
      "[500]\ttraining's ndcg@5: 0.436984\n",
      "[501]\ttraining's ndcg@5: 0.437042\n",
      "[502]\ttraining's ndcg@5: 0.437141\n",
      "[503]\ttraining's ndcg@5: 0.437228\n",
      "[504]\ttraining's ndcg@5: 0.437276\n",
      "[505]\ttraining's ndcg@5: 0.437321\n",
      "[506]\ttraining's ndcg@5: 0.437397\n",
      "[507]\ttraining's ndcg@5: 0.437469\n",
      "[508]\ttraining's ndcg@5: 0.4376\n",
      "[509]\ttraining's ndcg@5: 0.437656\n",
      "[510]\ttraining's ndcg@5: 0.437693\n",
      "[511]\ttraining's ndcg@5: 0.437744\n",
      "[512]\ttraining's ndcg@5: 0.437779\n",
      "[513]\ttraining's ndcg@5: 0.437841\n",
      "[514]\ttraining's ndcg@5: 0.437897\n",
      "[515]\ttraining's ndcg@5: 0.437939\n",
      "[516]\ttraining's ndcg@5: 0.437993\n",
      "[517]\ttraining's ndcg@5: 0.438057\n",
      "[518]\ttraining's ndcg@5: 0.438076\n",
      "[519]\ttraining's ndcg@5: 0.438177\n",
      "[520]\ttraining's ndcg@5: 0.438265\n",
      "[521]\ttraining's ndcg@5: 0.438313\n",
      "[522]\ttraining's ndcg@5: 0.438385\n",
      "[523]\ttraining's ndcg@5: 0.4385\n",
      "[524]\ttraining's ndcg@5: 0.438573\n",
      "[525]\ttraining's ndcg@5: 0.438603\n",
      "[526]\ttraining's ndcg@5: 0.438709\n",
      "[527]\ttraining's ndcg@5: 0.438756\n",
      "[528]\ttraining's ndcg@5: 0.438836\n",
      "[529]\ttraining's ndcg@5: 0.438892\n",
      "[530]\ttraining's ndcg@5: 0.43897\n",
      "[531]\ttraining's ndcg@5: 0.439016\n",
      "[532]\ttraining's ndcg@5: 0.439052\n",
      "[533]\ttraining's ndcg@5: 0.439086\n",
      "[534]\ttraining's ndcg@5: 0.43927\n",
      "[535]\ttraining's ndcg@5: 0.439368\n",
      "[536]\ttraining's ndcg@5: 0.439428\n",
      "[537]\ttraining's ndcg@5: 0.439503\n",
      "[538]\ttraining's ndcg@5: 0.439555\n",
      "[539]\ttraining's ndcg@5: 0.439559\n",
      "[540]\ttraining's ndcg@5: 0.439633\n",
      "[541]\ttraining's ndcg@5: 0.439688\n",
      "[542]\ttraining's ndcg@5: 0.439745\n",
      "[543]\ttraining's ndcg@5: 0.439787\n",
      "[544]\ttraining's ndcg@5: 0.439867\n",
      "[545]\ttraining's ndcg@5: 0.439968\n",
      "[546]\ttraining's ndcg@5: 0.440058\n",
      "[547]\ttraining's ndcg@5: 0.44009\n",
      "[548]\ttraining's ndcg@5: 0.440232\n",
      "[549]\ttraining's ndcg@5: 0.440293\n",
      "[550]\ttraining's ndcg@5: 0.440386\n",
      "[551]\ttraining's ndcg@5: 0.440486\n",
      "[552]\ttraining's ndcg@5: 0.440578\n",
      "[553]\ttraining's ndcg@5: 0.440641\n",
      "[554]\ttraining's ndcg@5: 0.440708\n",
      "[555]\ttraining's ndcg@5: 0.440832\n",
      "[556]\ttraining's ndcg@5: 0.440881\n",
      "[557]\ttraining's ndcg@5: 0.440911\n",
      "[558]\ttraining's ndcg@5: 0.440948\n",
      "[559]\ttraining's ndcg@5: 0.441038\n",
      "[560]\ttraining's ndcg@5: 0.44114\n",
      "[561]\ttraining's ndcg@5: 0.441171\n",
      "[562]\ttraining's ndcg@5: 0.441196\n",
      "[563]\ttraining's ndcg@5: 0.441263\n",
      "[564]\ttraining's ndcg@5: 0.441281\n",
      "[565]\ttraining's ndcg@5: 0.44132\n",
      "[566]\ttraining's ndcg@5: 0.441396\n",
      "[567]\ttraining's ndcg@5: 0.441458\n",
      "[568]\ttraining's ndcg@5: 0.441504\n",
      "[569]\ttraining's ndcg@5: 0.44155\n",
      "[570]\ttraining's ndcg@5: 0.441606\n",
      "[571]\ttraining's ndcg@5: 0.441649\n",
      "[572]\ttraining's ndcg@5: 0.441686\n",
      "[573]\ttraining's ndcg@5: 0.441737\n",
      "[574]\ttraining's ndcg@5: 0.441773\n",
      "[575]\ttraining's ndcg@5: 0.441817\n",
      "[576]\ttraining's ndcg@5: 0.441863\n",
      "[577]\ttraining's ndcg@5: 0.441869\n",
      "[578]\ttraining's ndcg@5: 0.441917\n",
      "[579]\ttraining's ndcg@5: 0.442061\n",
      "[580]\ttraining's ndcg@5: 0.442096\n",
      "[581]\ttraining's ndcg@5: 0.442198\n",
      "[582]\ttraining's ndcg@5: 0.442235\n",
      "[583]\ttraining's ndcg@5: 0.442266\n",
      "[584]\ttraining's ndcg@5: 0.442299\n",
      "[585]\ttraining's ndcg@5: 0.442337\n",
      "[586]\ttraining's ndcg@5: 0.442401\n",
      "[587]\ttraining's ndcg@5: 0.442432\n",
      "[588]\ttraining's ndcg@5: 0.442481\n",
      "[589]\ttraining's ndcg@5: 0.442533\n",
      "[590]\ttraining's ndcg@5: 0.442599\n",
      "[591]\ttraining's ndcg@5: 0.442661\n",
      "[592]\ttraining's ndcg@5: 0.44272\n",
      "[593]\ttraining's ndcg@5: 0.442833\n",
      "[594]\ttraining's ndcg@5: 0.44285\n",
      "[595]\ttraining's ndcg@5: 0.442901\n",
      "[596]\ttraining's ndcg@5: 0.442981\n",
      "[597]\ttraining's ndcg@5: 0.442989\n",
      "[598]\ttraining's ndcg@5: 0.443036\n",
      "[599]\ttraining's ndcg@5: 0.443075\n",
      "[600]\ttraining's ndcg@5: 0.443115\n",
      "[601]\ttraining's ndcg@5: 0.443211\n",
      "[602]\ttraining's ndcg@5: 0.443318\n",
      "[603]\ttraining's ndcg@5: 0.443351\n",
      "[604]\ttraining's ndcg@5: 0.443421\n",
      "[605]\ttraining's ndcg@5: 0.443456\n",
      "[606]\ttraining's ndcg@5: 0.443519\n",
      "[607]\ttraining's ndcg@5: 0.443562\n",
      "[608]\ttraining's ndcg@5: 0.443641\n",
      "[609]\ttraining's ndcg@5: 0.443669\n",
      "[610]\ttraining's ndcg@5: 0.443736\n",
      "[611]\ttraining's ndcg@5: 0.443786\n",
      "[612]\ttraining's ndcg@5: 0.443827\n",
      "[613]\ttraining's ndcg@5: 0.443913\n",
      "[614]\ttraining's ndcg@5: 0.443971\n",
      "[615]\ttraining's ndcg@5: 0.443968\n",
      "[616]\ttraining's ndcg@5: 0.444036\n",
      "[617]\ttraining's ndcg@5: 0.444097\n",
      "[618]\ttraining's ndcg@5: 0.444114\n",
      "[619]\ttraining's ndcg@5: 0.444173\n",
      "[620]\ttraining's ndcg@5: 0.444207\n",
      "[621]\ttraining's ndcg@5: 0.444254\n",
      "[622]\ttraining's ndcg@5: 0.444319\n",
      "[623]\ttraining's ndcg@5: 0.444378\n",
      "[624]\ttraining's ndcg@5: 0.444437\n",
      "[625]\ttraining's ndcg@5: 0.444469\n",
      "[626]\ttraining's ndcg@5: 0.444505\n",
      "[627]\ttraining's ndcg@5: 0.444576\n",
      "[628]\ttraining's ndcg@5: 0.444605\n",
      "[629]\ttraining's ndcg@5: 0.444655\n",
      "[630]\ttraining's ndcg@5: 0.444705\n",
      "[631]\ttraining's ndcg@5: 0.444767\n",
      "[632]\ttraining's ndcg@5: 0.444791\n",
      "[633]\ttraining's ndcg@5: 0.444846\n",
      "[634]\ttraining's ndcg@5: 0.444923\n",
      "[635]\ttraining's ndcg@5: 0.444989\n",
      "[636]\ttraining's ndcg@5: 0.445051\n",
      "[637]\ttraining's ndcg@5: 0.44511\n",
      "[638]\ttraining's ndcg@5: 0.44518\n",
      "[639]\ttraining's ndcg@5: 0.44523\n",
      "[640]\ttraining's ndcg@5: 0.445278\n",
      "[641]\ttraining's ndcg@5: 0.445332\n",
      "[642]\ttraining's ndcg@5: 0.445364\n",
      "[643]\ttraining's ndcg@5: 0.445411\n",
      "[644]\ttraining's ndcg@5: 0.445461\n",
      "[645]\ttraining's ndcg@5: 0.445451\n",
      "[646]\ttraining's ndcg@5: 0.445491\n",
      "[647]\ttraining's ndcg@5: 0.44556\n",
      "[648]\ttraining's ndcg@5: 0.445593\n",
      "[649]\ttraining's ndcg@5: 0.44572\n",
      "[650]\ttraining's ndcg@5: 0.445777\n",
      "[651]\ttraining's ndcg@5: 0.445831\n",
      "[652]\ttraining's ndcg@5: 0.44588\n",
      "[653]\ttraining's ndcg@5: 0.445949\n",
      "[654]\ttraining's ndcg@5: 0.445959\n",
      "[655]\ttraining's ndcg@5: 0.446008\n",
      "[656]\ttraining's ndcg@5: 0.446054\n",
      "Predicting...\n",
      "Done predicting\n"
     ]
    }
   ],
   "source": [
    "## Best run\n",
    "best_params = {'n_estimators': 878,\n",
    "               'num_leaves': 80,\n",
    "               'max_depth': 14,\n",
    "               'learning_rate': 0.018926700075124463,\n",
    "               'subsample': 0.6001819915274639,\n",
    "               'colsample_bytree': 0.7879556726353679,\n",
    "               'reg_alpha': 0.06065988852935483,\n",
    "               'reg_lambda': 0.14848222729700747,\n",
    "               'min_child_samples': 7,\n",
    "               'min_child_weight': 0.05206418484811052,\n",
    "               'val_size': 0.37752777983423735}\n",
    "\n",
    "# all but val_size in lgb_best_params\n",
    "val_size = best_params.pop('val_size')\n",
    "\n",
    "X_train_full, X_val_full, y_train_full, y_val_full, _ = train_test_split(df, 'target', test_size=val_size)\n",
    "\n",
    "_, desire_df_click_full = construct_desire(X_val_full)\n",
    "_, desire_df_book_full = construct_desire(X_val_full, target = 'booking_bool')\n",
    "\n",
    "X_train_full = merge_and_drop(X_train_full, desire_df_click_full, desire_df_book_full)\n",
    "df_test = merge_and_drop(df_test, desire_df_click_full, desire_df_book_full, drop=False)\n",
    "X_val_full.drop(['click_bool', 'booking_bool'], axis=1, inplace=True)\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Create dataset\n",
    "group_train = X_train_full.groupby('srch_id').size().values\n",
    "X_train_lgb = X_train_full.drop(['srch_id'], axis=1)\n",
    "# X_val_lgb = X_test.drop(['srch_id'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "ranker = lgb.LGBMRanker(**best_params)\n",
    "\n",
    "# Training the model\n",
    "ranker.fit(\n",
    "      X=X_train_lgb,\n",
    "      y=y_train_full,\n",
    "      group=group_train,\n",
    "      eval_set=[(X_train_lgb, y_train_full)],\n",
    "      eval_group=[group_train],\n",
    "      eval_at=[5])\n",
    "\n",
    "# Predicting the scores\n",
    "# test = X_val\n",
    "test = df_test\n",
    "test_input = test.drop(['srch_id'], axis=1)\n",
    "df_res = test\n",
    "\n",
    "\n",
    "print(\"Predicting...\")\n",
    "y_pred = ranker.predict(test_input)\n",
    "df_res['pred_grades'] = y_pred\n",
    "print(\"Done predicting\")\n",
    "\n",
    "df_res = df_res.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "\n",
    "df_res\n",
    "lgbm_submission_desire = df_res[['srch_id', 'prop_id']]\n",
    "lgbm_submission_desire.to_csv(config['PATH']['SUBMISSION_DIR'] + '/lgbm_submission_desire.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\src\\helpers\\helper_functions.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.sort_values(by=['srch_id', target_str], ascending=[True, False], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "best_params = {'n_estimators': 656,\n",
    "               'max_depth': 10,\n",
    "               'learning_rate': 0.04015011641981797,\n",
    "               'subsample': 0.5612356508273667,\n",
    "               'colsample_bytree': 0.6101457501984081,\n",
    "               'reg_alpha': 0.1408699896180758,\n",
    "               'reg_lambda': 0.008193149077132568,\n",
    "               'val_size': 0.5363941697030153,\n",
    "               'class_weight': 'balanced'}\n",
    "\n",
    "best_params = {'n_estimators': 878,\n",
    "               'num_leaves': 80,\n",
    "               'max_depth': 14,\n",
    "               'learning_rate': 0.018926700075124463,\n",
    "               'subsample': 0.6001819915274639,\n",
    "               'colsample_bytree': 0.7879556726353679,\n",
    "               'reg_alpha': 0.06065988852935483,\n",
    "               'reg_lambda': 0.14848222729700747,\n",
    "               'min_child_samples': 7,\n",
    "               'min_child_weight': 0.05206418484811052,\n",
    "               'val_size': 0.37752777983423735}\n",
    "               \n",
    "lgb_params = best_params.copy()\n",
    "val_size = lgb_params.pop('val_size')\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, test_ideal = train_val_test_split(df, 'target', test_size=.15, val_size=val_size, random_state=7)\n",
    "\n",
    "_, desire_df_click = construct_desire(X_val)\n",
    "_, desire_df_book = construct_desire(X_val, target = 'booking_bool')\n",
    "prop_counts = X_val['prop_id'].value_counts()\n",
    "prop_counts.name = 'prop_counts'\n",
    "srch_dest_counts = X_val['srch_destination_id'].value_counts()\n",
    "srch_dest_counts.name = 'srch_dest_counts'\n",
    "\n",
    "merge_df_list = [(desire_df_click, 'prop_id'), (desire_df_book, 'prop_id'), (prop_counts, 'prop_id'), (srch_dest_counts, 'srch_destination_id')]   \n",
    "\n",
    "X_train = merge_and_drop(X_train, merge_df_list)\n",
    "X_test = merge_and_drop(X_test, merge_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\wandb\\run-20230520_114919-tb03vwv8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vu-ml/DMT-2023/runs/tb03vwv8' target=\"_blank\">possibly-balanced-tiger-2</a></strong> to <a href='https://wandb.ai/vu-ml/DMT-2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vu-ml/DMT-2023' target=\"_blank\">https://wandb.ai/vu-ml/DMT-2023</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vu-ml/DMT-2023/runs/tb03vwv8' target=\"_blank\">https://wandb.ai/vu-ml/DMT-2023/runs/tb03vwv8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Done predicting\n",
      "result final:0.39197418623589503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>ndcg_final</td><td>▁</td></tr><tr><td>training_ndcg@5</td><td>▁▃▃▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>valid_1_ndcg@5</td><td>▁▅▇██████████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>655</td></tr><tr><td>ndcg_final</td><td>0.39197</td></tr><tr><td>training_ndcg@5</td><td>0.47089</td></tr><tr><td>valid_1_ndcg@5</td><td>0.37168</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">possibly-balanced-tiger-2</strong> at: <a href='https://wandb.ai/vu-ml/DMT-2023/runs/tb03vwv8' target=\"_blank\">https://wandb.ai/vu-ml/DMT-2023/runs/tb03vwv8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230520_114919-tb03vwv8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "# LightGBM ranker\n",
    "import lightgbm as lgb\n",
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback, log_summary\n",
    "\n",
    "# Create dataset\n",
    "group_train = X_train.groupby('srch_id').size().values\n",
    "group_val = X_test.groupby('srch_id').size().values\n",
    "\n",
    "X_train_lgb = X_train.drop(['srch_id'], axis=1)\n",
    "X_val_lgb = X_test.drop(['srch_id'], axis=1)\n",
    "\n",
    "\n",
    "ranker = lgb.LGBMRanker(**lgb_params)\n",
    "\n",
    "wandb.init(project='DMT-2023', config = best_params, notes='Now with class_weight = balanced', name='possibly-balanced-tiger-2')\n",
    "\n",
    "\n",
    "# Training the model\n",
    "ranker.fit(\n",
    "      X=X_train_lgb,\n",
    "      y=y_train,\n",
    "      group=group_train,\n",
    "      eval_set=[(X_train_lgb, y_train),(X_val_lgb, y_test)],\n",
    "      eval_group=[group_train, group_val],\n",
    "      eval_at=[5],\n",
    "      callbacks=[wandb_callback()])\n",
    "\n",
    "# Predicting the scores\n",
    "test = X_test.drop(['srch_id'], axis=1).copy()\n",
    "\n",
    "print(\"Predicting...\")\n",
    "y_pred = ranker.predict(test)\n",
    "print(\"Done predicting\")\n",
    "\n",
    "df_res = X_test.copy()\n",
    "df_res['pred_grades'] = y_pred\n",
    "df_res = df_res.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "df_res = df_res.merge(test_ideal, on=['srch_id', 'prop_id'], how='left')\n",
    "\n",
    "final_ndcg = calc_NDCG(test_ideal, df_res)\n",
    "wandb.log({'ndcg_final': final_ndcg})\n",
    "print(f\"result final:{final_ndcg}\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Done predicting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>prop_location_score2</th>\n",
       "      <th>prop_log_historical_price</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_length_of_stay</th>\n",
       "      <th>srch_booking_window</th>\n",
       "      <th>srch_adults_count</th>\n",
       "      <th>srch_children_count</th>\n",
       "      <th>srch_room_count</th>\n",
       "      <th>srch_saturday_night_bool</th>\n",
       "      <th>srch_query_affinity_score</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>comp1_rate</th>\n",
       "      <th>comp1_inv</th>\n",
       "      <th>comp1_rate_percent_diff</th>\n",
       "      <th>comp2_rate</th>\n",
       "      <th>comp2_inv</th>\n",
       "      <th>comp2_rate_percent_diff</th>\n",
       "      <th>comp3_rate</th>\n",
       "      <th>comp3_inv</th>\n",
       "      <th>comp3_rate_percent_diff</th>\n",
       "      <th>comp4_rate</th>\n",
       "      <th>comp4_inv</th>\n",
       "      <th>comp4_rate_percent_diff</th>\n",
       "      <th>comp5_rate</th>\n",
       "      <th>comp5_inv</th>\n",
       "      <th>comp5_rate_percent_diff</th>\n",
       "      <th>comp6_rate</th>\n",
       "      <th>comp6_inv</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>norm_price_usd_srch_id</th>\n",
       "      <th>norm_price_usd_prop_id</th>\n",
       "      <th>norm_price_usd_prop_country_id</th>\n",
       "      <th>norm_price_usd_srch_destination_id</th>\n",
       "      <th>norm_price_usd_srch_length_of_stay</th>\n",
       "      <th>norm_price_usd_srch_booking_window</th>\n",
       "      <th>norm_prop_starrating_srch_id</th>\n",
       "      <th>norm_prop_starrating_prop_id</th>\n",
       "      <th>norm_prop_starrating_prop_country_id</th>\n",
       "      <th>norm_prop_starrating_srch_destination_id</th>\n",
       "      <th>norm_prop_starrating_srch_length_of_stay</th>\n",
       "      <th>norm_prop_starrating_srch_booking_window</th>\n",
       "      <th>norm_prop_review_score_srch_id</th>\n",
       "      <th>norm_prop_review_score_prop_id</th>\n",
       "      <th>norm_prop_review_score_prop_country_id</th>\n",
       "      <th>norm_prop_review_score_srch_destination_id</th>\n",
       "      <th>norm_prop_review_score_srch_length_of_stay</th>\n",
       "      <th>norm_prop_review_score_srch_booking_window</th>\n",
       "      <th>norm_prop_location_score1_srch_id</th>\n",
       "      <th>norm_prop_location_score1_prop_id</th>\n",
       "      <th>norm_prop_location_score1_prop_country_id</th>\n",
       "      <th>norm_prop_location_score1_srch_destination_id</th>\n",
       "      <th>norm_prop_location_score1_srch_length_of_stay</th>\n",
       "      <th>norm_prop_location_score1_srch_booking_window</th>\n",
       "      <th>norm_prop_location_score2_srch_id</th>\n",
       "      <th>norm_prop_location_score2_prop_id</th>\n",
       "      <th>norm_prop_location_score2_prop_country_id</th>\n",
       "      <th>norm_prop_location_score2_srch_destination_id</th>\n",
       "      <th>norm_prop_location_score2_srch_length_of_stay</th>\n",
       "      <th>norm_prop_location_score2_srch_booking_window</th>\n",
       "      <th>rank_price_usd</th>\n",
       "      <th>rank_prop_starrating</th>\n",
       "      <th>rank_prop_review_score</th>\n",
       "      <th>rank_prop_location_score1</th>\n",
       "      <th>rank_prop_location_score2</th>\n",
       "      <th>usd_diff</th>\n",
       "      <th>star_diff</th>\n",
       "      <th>pred_grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>99484</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>4.54</td>\n",
       "      <td>69.00</td>\n",
       "      <td>1</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.671318</td>\n",
       "      <td>-0.689460</td>\n",
       "      <td>-0.038936</td>\n",
       "      <td>-0.608633</td>\n",
       "      <td>-0.031497</td>\n",
       "      <td>-0.256239</td>\n",
       "      <td>0.435686</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.423708</td>\n",
       "      <td>-0.06239</td>\n",
       "      <td>-0.152279</td>\n",
       "      <td>-0.018342</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.141606</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>0.221727</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>-0.866188</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.146292</td>\n",
       "      <td>-0.225135</td>\n",
       "      <td>-0.134617</td>\n",
       "      <td>-0.266470</td>\n",
       "      <td>1.211751</td>\n",
       "      <td>1.546040</td>\n",
       "      <td>0.596490</td>\n",
       "      <td>1.240322</td>\n",
       "      <td>0.633046</td>\n",
       "      <td>0.570355</td>\n",
       "      <td>20.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.128720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>61934</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>4.69</td>\n",
       "      <td>88.88</td>\n",
       "      <td>1</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.133106</td>\n",
       "      <td>-0.446593</td>\n",
       "      <td>-0.031811</td>\n",
       "      <td>-0.023315</td>\n",
       "      <td>-0.025488</td>\n",
       "      <td>-0.194912</td>\n",
       "      <td>0.435686</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.423708</td>\n",
       "      <td>-0.06239</td>\n",
       "      <td>-0.152279</td>\n",
       "      <td>0.513567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750018</td>\n",
       "      <td>0.638288</td>\n",
       "      <td>0.713598</td>\n",
       "      <td>0.701668</td>\n",
       "      <td>0.761925</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.210782</td>\n",
       "      <td>0.703219</td>\n",
       "      <td>0.207293</td>\n",
       "      <td>0.064784</td>\n",
       "      <td>1.528994</td>\n",
       "      <td>1.688049</td>\n",
       "      <td>0.753974</td>\n",
       "      <td>1.568926</td>\n",
       "      <td>0.793864</td>\n",
       "      <td>0.723864</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.893853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>54937</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>4.75</td>\n",
       "      <td>83.30</td>\n",
       "      <td>1</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.284174</td>\n",
       "      <td>-0.125656</td>\n",
       "      <td>-0.033811</td>\n",
       "      <td>-0.187605</td>\n",
       "      <td>-0.027175</td>\n",
       "      <td>-0.212125</td>\n",
       "      <td>0.435686</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.423708</td>\n",
       "      <td>-0.06239</td>\n",
       "      <td>-0.152279</td>\n",
       "      <td>-0.018342</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.141606</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>0.221727</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>-1.929446</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.379483</td>\n",
       "      <td>-0.831407</td>\n",
       "      <td>-0.357905</td>\n",
       "      <td>-0.482800</td>\n",
       "      <td>0.515907</td>\n",
       "      <td>1.670272</td>\n",
       "      <td>0.251061</td>\n",
       "      <td>0.519556</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.233647</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.718350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>34263</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>4.63</td>\n",
       "      <td>79.00</td>\n",
       "      <td>0</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.400588</td>\n",
       "      <td>-0.882482</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.314208</td>\n",
       "      <td>-0.028475</td>\n",
       "      <td>-0.225390</td>\n",
       "      <td>0.435686</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.423708</td>\n",
       "      <td>-0.06239</td>\n",
       "      <td>-0.152279</td>\n",
       "      <td>0.513567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750018</td>\n",
       "      <td>0.638288</td>\n",
       "      <td>0.713598</td>\n",
       "      <td>0.701668</td>\n",
       "      <td>1.426461</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.356526</td>\n",
       "      <td>1.082139</td>\n",
       "      <td>0.346848</td>\n",
       "      <td>0.199990</td>\n",
       "      <td>0.060279</td>\n",
       "      <td>1.005503</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>0.047610</td>\n",
       "      <td>0.049333</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.596245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>24194</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>4.72</td>\n",
       "      <td>79.00</td>\n",
       "      <td>0</td>\n",
       "      <td>19222</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.400588</td>\n",
       "      <td>-0.492400</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.314208</td>\n",
       "      <td>-0.028475</td>\n",
       "      <td>-0.225390</td>\n",
       "      <td>0.435686</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.423708</td>\n",
       "      <td>-0.06239</td>\n",
       "      <td>-0.152279</td>\n",
       "      <td>0.513567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750018</td>\n",
       "      <td>0.638288</td>\n",
       "      <td>0.713598</td>\n",
       "      <td>0.701668</td>\n",
       "      <td>0.928059</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.247218</td>\n",
       "      <td>0.797949</td>\n",
       "      <td>0.242182</td>\n",
       "      <td>0.098586</td>\n",
       "      <td>1.091643</td>\n",
       "      <td>1.057683</td>\n",
       "      <td>0.536866</td>\n",
       "      <td>1.115912</td>\n",
       "      <td>0.572159</td>\n",
       "      <td>0.512237</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.514031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959181</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>94437</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>4.64</td>\n",
       "      <td>66.07</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.657494</td>\n",
       "      <td>0.188880</td>\n",
       "      <td>-0.245072</td>\n",
       "      <td>-0.657494</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>-0.573559</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.817248</td>\n",
       "      <td>-1.387905</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.599454</td>\n",
       "      <td>-1.387905</td>\n",
       "      <td>-3.689045</td>\n",
       "      <td>-3.678032</td>\n",
       "      <td>1.635425</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.181605</td>\n",
       "      <td>1.635425</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.113572</td>\n",
       "      <td>-0.296757</td>\n",
       "      <td>2.267787</td>\n",
       "      <td>0.337793</td>\n",
       "      <td>-0.296757</td>\n",
       "      <td>-0.257804</td>\n",
       "      <td>-0.211032</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.020801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959177</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>29018</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>4.64</td>\n",
       "      <td>70.05</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.404765</td>\n",
       "      <td>0.442053</td>\n",
       "      <td>-0.223651</td>\n",
       "      <td>-0.404765</td>\n",
       "      <td>-0.009747</td>\n",
       "      <td>-0.545107</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.817248</td>\n",
       "      <td>0.981689</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.123349</td>\n",
       "      <td>0.981689</td>\n",
       "      <td>1.165966</td>\n",
       "      <td>1.186891</td>\n",
       "      <td>0.607002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.483648</td>\n",
       "      <td>0.607002</td>\n",
       "      <td>-0.244004</td>\n",
       "      <td>-0.140976</td>\n",
       "      <td>-0.631899</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>-0.113008</td>\n",
       "      <td>-0.631899</td>\n",
       "      <td>-0.497846</td>\n",
       "      <td>-0.462914</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.072454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959182</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>99509</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>4.64</td>\n",
       "      <td>82.06</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>0.357866</td>\n",
       "      <td>-0.041746</td>\n",
       "      <td>-0.159009</td>\n",
       "      <td>0.357866</td>\n",
       "      <td>-0.009236</td>\n",
       "      <td>-0.459249</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.817248</td>\n",
       "      <td>0.744729</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.851069</td>\n",
       "      <td>0.744729</td>\n",
       "      <td>0.680465</td>\n",
       "      <td>0.700399</td>\n",
       "      <td>-0.692059</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.865176</td>\n",
       "      <td>-0.692059</td>\n",
       "      <td>-0.556186</td>\n",
       "      <td>-0.462510</td>\n",
       "      <td>-0.798610</td>\n",
       "      <td>3.175426</td>\n",
       "      <td>-0.337252</td>\n",
       "      <td>-0.798610</td>\n",
       "      <td>-0.617252</td>\n",
       "      <td>-0.588210</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.283133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959178</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>32019</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>4.53</td>\n",
       "      <td>66.07</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.657494</td>\n",
       "      <td>2.642323</td>\n",
       "      <td>-0.245072</td>\n",
       "      <td>-0.657494</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>-0.573559</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.817248</td>\n",
       "      <td>0.270811</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.306508</td>\n",
       "      <td>0.270811</td>\n",
       "      <td>-0.290537</td>\n",
       "      <td>-0.272586</td>\n",
       "      <td>0.390491</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.547236</td>\n",
       "      <td>0.390491</td>\n",
       "      <td>-0.296035</td>\n",
       "      <td>-0.194565</td>\n",
       "      <td>-0.620727</td>\n",
       "      <td>0.575903</td>\n",
       "      <td>-0.097981</td>\n",
       "      <td>-0.620727</td>\n",
       "      <td>-0.489845</td>\n",
       "      <td>-0.454518</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.334332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959180</th>\n",
       "      <td>332787</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117</td>\n",
       "      <td>35240</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>4.64</td>\n",
       "      <td>73.91</td>\n",
       "      <td>0</td>\n",
       "      <td>19246</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.159656</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.202875</td>\n",
       "      <td>-0.159656</td>\n",
       "      <td>-0.009583</td>\n",
       "      <td>-0.517513</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.817248</td>\n",
       "      <td>-1.387905</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.599454</td>\n",
       "      <td>-1.387905</td>\n",
       "      <td>-3.689045</td>\n",
       "      <td>-3.678032</td>\n",
       "      <td>-1.476908</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.095682</td>\n",
       "      <td>-1.476908</td>\n",
       "      <td>-0.744796</td>\n",
       "      <td>-0.656770</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.082730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4959183 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id  site_id  visitor_location_country_id   \n",
       "23             1       24                          216  \\\n",
       "12             1       24                          216   \n",
       "9              1       24                          216   \n",
       "6              1       24                          216   \n",
       "4              1       24                          216   \n",
       "...          ...      ...                          ...   \n",
       "4959181   332787       24                          216   \n",
       "4959177   332787       24                          216   \n",
       "4959182   332787       24                          216   \n",
       "4959178   332787       24                          216   \n",
       "4959180   332787       24                          216   \n",
       "\n",
       "         visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id   \n",
       "23                          -1.0                  -1.0              219  \\\n",
       "12                          -1.0                  -1.0              219   \n",
       "9                           -1.0                  -1.0              219   \n",
       "6                           -1.0                  -1.0              219   \n",
       "4                           -1.0                  -1.0              219   \n",
       "...                          ...                   ...              ...   \n",
       "4959181                     -1.0                  -1.0              117   \n",
       "4959177                     -1.0                  -1.0              117   \n",
       "4959182                     -1.0                  -1.0              117   \n",
       "4959178                     -1.0                  -1.0              117   \n",
       "4959180                     -1.0                  -1.0              117   \n",
       "\n",
       "         prop_id  prop_starrating  prop_review_score  prop_brand_bool   \n",
       "23         99484                3                4.0                1  \\\n",
       "12         61934                3                4.5                1   \n",
       "9          54937                3                4.0                1   \n",
       "6          34263                3                4.5                1   \n",
       "4          24194                3                4.5                1   \n",
       "...          ...              ...                ...              ...   \n",
       "4959181    94437                4                0.0                0   \n",
       "4959177    29018                4                5.0                1   \n",
       "4959182    99509                4                4.5                1   \n",
       "4959178    32019                4                3.5                0   \n",
       "4959180    35240                4                0.0                0   \n",
       "\n",
       "         prop_location_score1  prop_location_score2   \n",
       "23                       2.40                0.2182  \\\n",
       "12                       2.89                0.2425   \n",
       "9                        2.08                0.1649   \n",
       "6                        3.09                0.1300   \n",
       "4                        2.94                0.2090   \n",
       "...                       ...                   ...   \n",
       "4959181                  2.94                0.0928   \n",
       "4959177                  2.56                0.0538   \n",
       "4959182                  2.08                0.0344   \n",
       "4959178                  2.48                0.0551   \n",
       "4959180                  1.79               -1.0000   \n",
       "\n",
       "         prop_log_historical_price  price_usd  promotion_flag   \n",
       "23                            4.54      69.00               1  \\\n",
       "12                            4.69      88.88               1   \n",
       "9                             4.75      83.30               1   \n",
       "6                             4.63      79.00               0   \n",
       "4                             4.72      79.00               0   \n",
       "...                            ...        ...             ...   \n",
       "4959181                       4.64      66.07               0   \n",
       "4959177                       4.64      70.05               0   \n",
       "4959182                       4.64      82.06               0   \n",
       "4959178                       4.53      66.07               0   \n",
       "4959180                       4.64      73.91               0   \n",
       "\n",
       "         srch_destination_id  srch_length_of_stay  srch_booking_window   \n",
       "23                     19222                    1                   10  \\\n",
       "12                     19222                    1                   10   \n",
       "9                      19222                    1                   10   \n",
       "6                      19222                    1                   10   \n",
       "4                      19222                    1                   10   \n",
       "...                      ...                  ...                  ...   \n",
       "4959181                19246                    2                    7   \n",
       "4959177                19246                    2                    7   \n",
       "4959182                19246                    2                    7   \n",
       "4959178                19246                    2                    7   \n",
       "4959180                19246                    2                    7   \n",
       "\n",
       "         srch_adults_count  srch_children_count  srch_room_count   \n",
       "23                       2                    0                1  \\\n",
       "12                       2                    0                1   \n",
       "9                        2                    0                1   \n",
       "6                        2                    0                1   \n",
       "4                        2                    0                1   \n",
       "...                    ...                  ...              ...   \n",
       "4959181                  1                    0                1   \n",
       "4959177                  1                    0                1   \n",
       "4959182                  1                    0                1   \n",
       "4959178                  1                    0                1   \n",
       "4959180                  1                    0                1   \n",
       "\n",
       "         srch_saturday_night_bool  srch_query_affinity_score   \n",
       "23                              0                       -1.0  \\\n",
       "12                              0                       -1.0   \n",
       "9                               0                       -1.0   \n",
       "6                               0                       -1.0   \n",
       "4                               0                       -1.0   \n",
       "...                           ...                        ...   \n",
       "4959181                         0                       -1.0   \n",
       "4959177                         0                       -1.0   \n",
       "4959182                         0                       -1.0   \n",
       "4959178                         0                       -1.0   \n",
       "4959180                         0                       -1.0   \n",
       "\n",
       "         orig_destination_distance  comp1_rate  comp1_inv   \n",
       "23                            -1.0        -1.0       -1.0  \\\n",
       "12                            -1.0        -1.0       -1.0   \n",
       "9                             -1.0        -1.0       -1.0   \n",
       "6                             -1.0        -1.0       -1.0   \n",
       "4                             -1.0        -1.0       -1.0   \n",
       "...                            ...         ...        ...   \n",
       "4959181                       -1.0        -1.0       -1.0   \n",
       "4959177                       -1.0        -1.0       -1.0   \n",
       "4959182                       -1.0        -1.0       -1.0   \n",
       "4959178                       -1.0        -1.0       -1.0   \n",
       "4959180                       -1.0        -1.0       -1.0   \n",
       "\n",
       "         comp1_rate_percent_diff  comp2_rate  comp2_inv   \n",
       "23                          -1.0         1.0        0.0  \\\n",
       "12                          -1.0         0.0        0.0   \n",
       "9                           -1.0        -1.0       -1.0   \n",
       "6                           -1.0         0.0        0.0   \n",
       "4                           -1.0         0.0        0.0   \n",
       "...                          ...         ...        ...   \n",
       "4959181                     -1.0         1.0        0.0   \n",
       "4959177                     -1.0         1.0        0.0   \n",
       "4959182                     -1.0         0.0        0.0   \n",
       "4959178                     -1.0         1.0        0.0   \n",
       "4959180                     -1.0         1.0        0.0   \n",
       "\n",
       "         comp2_rate_percent_diff  comp3_rate  comp3_inv   \n",
       "23                           2.0        -1.0       -1.0  \\\n",
       "12                          -1.0        -1.0       -1.0   \n",
       "9                           -1.0        -1.0       -1.0   \n",
       "6                            6.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959181                     43.0         1.0        0.0   \n",
       "4959177                     69.0        -1.0       -1.0   \n",
       "4959182                     -1.0         0.0        0.0   \n",
       "4959178                     22.0         1.0        0.0   \n",
       "4959180                     55.0         0.0        0.0   \n",
       "\n",
       "         comp3_rate_percent_diff  comp4_rate  comp4_inv   \n",
       "23                          -1.0        -1.0       -1.0  \\\n",
       "12                          -1.0        -1.0       -1.0   \n",
       "9                           -1.0        -1.0       -1.0   \n",
       "6                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959181                     43.0        -1.0        0.0   \n",
       "4959177                     -1.0         0.0        0.0   \n",
       "4959182                     -1.0         0.0        0.0   \n",
       "4959178                    127.0        -1.0        0.0   \n",
       "4959180                     -1.0         0.0        0.0   \n",
       "\n",
       "         comp4_rate_percent_diff  comp5_rate  comp5_inv   \n",
       "23                          -1.0         0.0        0.0  \\\n",
       "12                          -1.0        -1.0       -1.0   \n",
       "9                           -1.0         0.0        0.0   \n",
       "6                           -1.0         0.0        0.0   \n",
       "4                           -1.0         0.0        0.0   \n",
       "...                          ...         ...        ...   \n",
       "4959181                     12.0        -1.0        0.0   \n",
       "4959177                     16.0         0.0        0.0   \n",
       "4959182                     16.0         0.0        0.0   \n",
       "4959178                     27.0         1.0        0.0   \n",
       "4959180                     16.0         0.0        0.0   \n",
       "\n",
       "         comp5_rate_percent_diff  comp6_rate  comp6_inv   \n",
       "23                          -1.0        -1.0       -1.0  \\\n",
       "12                          -1.0        -1.0       -1.0   \n",
       "9                           -1.0        -1.0       -1.0   \n",
       "6                            6.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959181                     12.0        -1.0       -1.0   \n",
       "4959177                     -1.0        -1.0       -1.0   \n",
       "4959182                     -1.0        -1.0       -1.0   \n",
       "4959178                     22.0        -1.0       -1.0   \n",
       "4959180                      3.0        -1.0       -1.0   \n",
       "\n",
       "         comp6_rate_percent_diff  comp7_rate  comp7_inv   \n",
       "23                          -1.0        -1.0       -1.0  \\\n",
       "12                          -1.0        -1.0       -1.0   \n",
       "9                           -1.0        -1.0       -1.0   \n",
       "6                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959181                     -1.0        -1.0       -1.0   \n",
       "4959177                     -1.0        -1.0       -1.0   \n",
       "4959182                     -1.0        -1.0       -1.0   \n",
       "4959178                     -1.0        -1.0       -1.0   \n",
       "4959180                     -1.0        -1.0       -1.0   \n",
       "\n",
       "         comp7_rate_percent_diff  comp8_rate  comp8_inv   \n",
       "23                          -1.0        -1.0       -1.0  \\\n",
       "12                          -1.0        -1.0       -1.0   \n",
       "9                           -1.0        -1.0       -1.0   \n",
       "6                           -1.0        -1.0       -1.0   \n",
       "4                           -1.0        -1.0       -1.0   \n",
       "...                          ...         ...        ...   \n",
       "4959181                     -1.0        -1.0       -1.0   \n",
       "4959177                     -1.0        -1.0       -1.0   \n",
       "4959182                     -1.0        -1.0       -1.0   \n",
       "4959178                     -1.0        -1.0       -1.0   \n",
       "4959180                     -1.0        -1.0       -1.0   \n",
       "\n",
       "         comp8_rate_percent_diff  month  day  hour  norm_price_usd_srch_id   \n",
       "23                          -1.0      2    2    15               -0.671318  \\\n",
       "12                          -1.0      2    2    15               -0.133106   \n",
       "9                           -1.0      2    2    15               -0.284174   \n",
       "6                           -1.0      2    2    15               -0.400588   \n",
       "4                           -1.0      2    2    15               -0.400588   \n",
       "...                          ...    ...  ...   ...                     ...   \n",
       "4959181                     -1.0      5   21    11               -0.657494   \n",
       "4959177                     -1.0      5   21    11               -0.404765   \n",
       "4959182                     -1.0      5   21    11                0.357866   \n",
       "4959178                     -1.0      5   21    11               -0.657494   \n",
       "4959180                     -1.0      5   21    11               -0.159656   \n",
       "\n",
       "         norm_price_usd_prop_id  norm_price_usd_prop_country_id   \n",
       "23                    -0.689460                       -0.038936  \\\n",
       "12                    -0.446593                       -0.031811   \n",
       "9                     -0.125656                       -0.033811   \n",
       "6                     -0.882482                       -0.035352   \n",
       "4                     -0.492400                       -0.035352   \n",
       "...                         ...                             ...   \n",
       "4959181                0.188880                       -0.245072   \n",
       "4959177                0.442053                       -0.223651   \n",
       "4959182               -0.041746                       -0.159009   \n",
       "4959178                2.642323                       -0.245072   \n",
       "4959180                0.707107                       -0.202875   \n",
       "\n",
       "         norm_price_usd_srch_destination_id   \n",
       "23                                -0.608633  \\\n",
       "12                                -0.023315   \n",
       "9                                 -0.187605   \n",
       "6                                 -0.314208   \n",
       "4                                 -0.314208   \n",
       "...                                     ...   \n",
       "4959181                           -0.657494   \n",
       "4959177                           -0.404765   \n",
       "4959182                            0.357866   \n",
       "4959178                           -0.657494   \n",
       "4959180                           -0.159656   \n",
       "\n",
       "         norm_price_usd_srch_length_of_stay   \n",
       "23                                -0.031497  \\\n",
       "12                                -0.025488   \n",
       "9                                 -0.027175   \n",
       "6                                 -0.028475   \n",
       "4                                 -0.028475   \n",
       "...                                     ...   \n",
       "4959181                           -0.009917   \n",
       "4959177                           -0.009747   \n",
       "4959182                           -0.009236   \n",
       "4959178                           -0.009917   \n",
       "4959180                           -0.009583   \n",
       "\n",
       "         norm_price_usd_srch_booking_window  norm_prop_starrating_srch_id   \n",
       "23                                -0.256239                      0.435686  \\\n",
       "12                                -0.194912                      0.435686   \n",
       "9                                 -0.212125                      0.435686   \n",
       "6                                 -0.225390                      0.435686   \n",
       "4                                 -0.225390                      0.435686   \n",
       "...                                     ...                           ...   \n",
       "4959181                           -0.573559                     -0.377964   \n",
       "4959177                           -0.545107                     -0.377964   \n",
       "4959182                           -0.459249                     -0.377964   \n",
       "4959178                           -0.573559                     -0.377964   \n",
       "4959180                           -0.517513                     -0.377964   \n",
       "\n",
       "         norm_prop_starrating_prop_id  norm_prop_starrating_prop_country_id   \n",
       "23                               -1.0                              0.022244  \\\n",
       "12                               -1.0                              0.022244   \n",
       "9                                -1.0                              0.022244   \n",
       "6                                -1.0                              0.022244   \n",
       "4                                -1.0                              0.022244   \n",
       "...                               ...                                   ...   \n",
       "4959181                          -1.0                              0.068374   \n",
       "4959177                          -1.0                              0.068374   \n",
       "4959182                          -1.0                              0.068374   \n",
       "4959178                          -1.0                              0.068374   \n",
       "4959180                          -1.0                              0.068374   \n",
       "\n",
       "         norm_prop_starrating_srch_destination_id   \n",
       "23                                       0.423708  \\\n",
       "12                                       0.423708   \n",
       "9                                        0.423708   \n",
       "6                                        0.423708   \n",
       "4                                        0.423708   \n",
       "...                                           ...   \n",
       "4959181                                 -0.377964   \n",
       "4959177                                 -0.377964   \n",
       "4959182                                 -0.377964   \n",
       "4959178                                 -0.377964   \n",
       "4959180                                 -0.377964   \n",
       "\n",
       "         norm_prop_starrating_srch_length_of_stay   \n",
       "23                                       -0.06239  \\\n",
       "12                                       -0.06239   \n",
       "9                                        -0.06239   \n",
       "6                                        -0.06239   \n",
       "4                                        -0.06239   \n",
       "...                                           ...   \n",
       "4959181                                   0.77001   \n",
       "4959177                                   0.77001   \n",
       "4959182                                   0.77001   \n",
       "4959178                                   0.77001   \n",
       "4959180                                   0.77001   \n",
       "\n",
       "         norm_prop_starrating_srch_booking_window   \n",
       "23                                      -0.152279  \\\n",
       "12                                      -0.152279   \n",
       "9                                       -0.152279   \n",
       "6                                       -0.152279   \n",
       "4                                       -0.152279   \n",
       "...                                           ...   \n",
       "4959181                                  0.817248   \n",
       "4959177                                  0.817248   \n",
       "4959182                                  0.817248   \n",
       "4959178                                  0.817248   \n",
       "4959180                                  0.817248   \n",
       "\n",
       "         norm_prop_review_score_srch_id  norm_prop_review_score_prop_id   \n",
       "23                            -0.018342                            -1.0  \\\n",
       "12                             0.513567                            -1.0   \n",
       "9                             -0.018342                            -1.0   \n",
       "6                              0.513567                            -1.0   \n",
       "4                              0.513567                            -1.0   \n",
       "...                                 ...                             ...   \n",
       "4959181                       -1.387905                            -1.0   \n",
       "4959177                        0.981689                            -1.0   \n",
       "4959182                        0.744729                            -1.0   \n",
       "4959178                        0.270811                            -1.0   \n",
       "4959180                       -1.387905                            -1.0   \n",
       "\n",
       "         norm_prop_review_score_prop_country_id   \n",
       "23                                     0.141606  \\\n",
       "12                                     0.750018   \n",
       "9                                      0.141606   \n",
       "6                                      0.750018   \n",
       "4                                      0.750018   \n",
       "...                                         ...   \n",
       "4959181                               -1.599454   \n",
       "4959177                                1.123349   \n",
       "4959182                                0.851069   \n",
       "4959178                                0.306508   \n",
       "4959180                               -1.599454   \n",
       "\n",
       "         norm_prop_review_score_srch_destination_id   \n",
       "23                                         0.056152  \\\n",
       "12                                         0.638288   \n",
       "9                                          0.056152   \n",
       "6                                          0.638288   \n",
       "4                                          0.638288   \n",
       "...                                             ...   \n",
       "4959181                                   -1.387905   \n",
       "4959177                                    0.981689   \n",
       "4959182                                    0.744729   \n",
       "4959178                                    0.270811   \n",
       "4959180                                   -1.387905   \n",
       "\n",
       "         norm_prop_review_score_srch_length_of_stay   \n",
       "23                                         0.221727  \\\n",
       "12                                         0.713598   \n",
       "9                                          0.221727   \n",
       "6                                          0.713598   \n",
       "4                                          0.713598   \n",
       "...                                             ...   \n",
       "4959181                                   -3.689045   \n",
       "4959177                                    1.165966   \n",
       "4959182                                    0.680465   \n",
       "4959178                                   -0.290537   \n",
       "4959180                                   -3.689045   \n",
       "\n",
       "         norm_prop_review_score_srch_booking_window   \n",
       "23                                         0.208696  \\\n",
       "12                                         0.701668   \n",
       "9                                          0.208696   \n",
       "6                                          0.701668   \n",
       "4                                          0.701668   \n",
       "...                                             ...   \n",
       "4959181                                   -3.678032   \n",
       "4959177                                    1.186891   \n",
       "4959182                                    0.700399   \n",
       "4959178                                   -0.272586   \n",
       "4959180                                   -3.678032   \n",
       "\n",
       "         norm_prop_location_score1_srch_id  norm_prop_location_score1_prop_id   \n",
       "23                               -0.866188                               -1.0  \\\n",
       "12                                0.761925                               -1.0   \n",
       "9                                -1.929446                               -1.0   \n",
       "6                                 1.426461                               -1.0   \n",
       "4                                 0.928059                               -1.0   \n",
       "...                                    ...                                ...   \n",
       "4959181                           1.635425                               -1.0   \n",
       "4959177                           0.607002                               -1.0   \n",
       "4959182                          -0.692059                               -1.0   \n",
       "4959178                           0.390491                               -1.0   \n",
       "4959180                          -1.476908                               -1.0   \n",
       "\n",
       "         norm_prop_location_score1_prop_country_id   \n",
       "23                                       -0.146292  \\\n",
       "12                                        0.210782   \n",
       "9                                        -0.379483   \n",
       "6                                         0.356526   \n",
       "4                                         0.247218   \n",
       "...                                            ...   \n",
       "4959181                                  -0.181605   \n",
       "4959177                                  -0.483648   \n",
       "4959182                                  -0.865176   \n",
       "4959178                                  -0.547236   \n",
       "4959180                                  -1.095682   \n",
       "\n",
       "         norm_prop_location_score1_srch_destination_id   \n",
       "23                                           -0.225135  \\\n",
       "12                                            0.703219   \n",
       "9                                            -0.831407   \n",
       "6                                             1.082139   \n",
       "4                                             0.797949   \n",
       "...                                                ...   \n",
       "4959181                                       1.635425   \n",
       "4959177                                       0.607002   \n",
       "4959182                                      -0.692059   \n",
       "4959178                                       0.390491   \n",
       "4959180                                      -1.476908   \n",
       "\n",
       "         norm_prop_location_score1_srch_length_of_stay   \n",
       "23                                           -0.134617  \\\n",
       "12                                            0.207293   \n",
       "9                                            -0.357905   \n",
       "6                                             0.346848   \n",
       "4                                             0.242182   \n",
       "...                                                ...   \n",
       "4959181                                       0.003139   \n",
       "4959177                                      -0.244004   \n",
       "4959182                                      -0.556186   \n",
       "4959178                                      -0.296035   \n",
       "4959180                                      -0.744796   \n",
       "\n",
       "         norm_prop_location_score1_srch_booking_window   \n",
       "23                                           -0.266470  \\\n",
       "12                                            0.064784   \n",
       "9                                            -0.482800   \n",
       "6                                             0.199990   \n",
       "4                                             0.098586   \n",
       "...                                                ...   \n",
       "4959181                                       0.113572   \n",
       "4959177                                      -0.140976   \n",
       "4959182                                      -0.462510   \n",
       "4959178                                      -0.194565   \n",
       "4959180                                      -0.656770   \n",
       "\n",
       "         norm_prop_location_score2_srch_id  norm_prop_location_score2_prop_id   \n",
       "23                                1.211751                           1.546040  \\\n",
       "12                                1.528994                           1.688049   \n",
       "9                                 0.515907                           1.670272   \n",
       "6                                 0.060279                           1.005503   \n",
       "4                                 1.091643                           1.057683   \n",
       "...                                    ...                                ...   \n",
       "4959181                          -0.296757                           2.267787   \n",
       "4959177                          -0.631899                           1.788854   \n",
       "4959182                          -0.798610                           3.175426   \n",
       "4959178                          -0.620727                           0.575903   \n",
       "4959180                          -1.000000                          -1.000000   \n",
       "\n",
       "         norm_prop_location_score2_prop_country_id   \n",
       "23                                        0.596490  \\\n",
       "12                                        0.753974   \n",
       "9                                         0.251061   \n",
       "6                                         0.024880   \n",
       "4                                         0.536866   \n",
       "...                                            ...   \n",
       "4959181                                   0.337793   \n",
       "4959177                                  -0.113008   \n",
       "4959182                                  -0.337252   \n",
       "4959178                                  -0.097981   \n",
       "4959180                                  -1.000000   \n",
       "\n",
       "         norm_prop_location_score2_srch_destination_id   \n",
       "23                                            1.240322  \\\n",
       "12                                            1.568926   \n",
       "9                                             0.519556   \n",
       "6                                             0.047610   \n",
       "4                                             1.115912   \n",
       "...                                                ...   \n",
       "4959181                                      -0.296757   \n",
       "4959177                                      -0.631899   \n",
       "4959182                                      -0.798610   \n",
       "4959178                                      -0.620727   \n",
       "4959180                                      -1.000000   \n",
       "\n",
       "         norm_prop_location_score2_srch_length_of_stay   \n",
       "23                                            0.633046  \\\n",
       "12                                            0.793864   \n",
       "9                                             0.280303   \n",
       "6                                             0.049333   \n",
       "4                                             0.572159   \n",
       "...                                                ...   \n",
       "4959181                                      -0.257804   \n",
       "4959177                                      -0.497846   \n",
       "4959182                                      -0.617252   \n",
       "4959178                                      -0.489845   \n",
       "4959180                                      -1.000000   \n",
       "\n",
       "         norm_prop_location_score2_srch_booking_window  rank_price_usd   \n",
       "23                                            0.570355            20.5  \\\n",
       "12                                            0.723864            14.0   \n",
       "9                                             0.233647            16.0   \n",
       "6                                             0.013175            18.0   \n",
       "4                                             0.512237            18.0   \n",
       "...                                                ...             ...   \n",
       "4959181                                      -0.211032             6.5   \n",
       "4959177                                      -0.462914             4.0   \n",
       "4959182                                      -0.588210             2.0   \n",
       "4959178                                      -0.454518             6.5   \n",
       "4959180                                      -1.000000             3.0   \n",
       "\n",
       "         rank_prop_starrating  rank_prop_review_score   \n",
       "23                       11.5                    20.0  \\\n",
       "12                       11.5                     9.5   \n",
       "9                        11.5                    20.0   \n",
       "6                        11.5                     9.5   \n",
       "4                        11.5                     9.5   \n",
       "...                       ...                     ...   \n",
       "4959181                   4.5                     6.5   \n",
       "4959177                   4.5                     1.0   \n",
       "4959182                   4.5                     2.5   \n",
       "4959178                   4.5                     4.0   \n",
       "4959180                   4.5                     6.5   \n",
       "\n",
       "         rank_prop_location_score1  rank_prop_location_score2  usd_diff   \n",
       "23                            22.0                        6.0      -1.0  \\\n",
       "12                             7.0                        1.0      -1.0   \n",
       "9                             28.5                       11.0      -1.0   \n",
       "6                              1.0                       13.0      -1.0   \n",
       "4                              4.5                        7.5      -1.0   \n",
       "...                            ...                        ...       ...   \n",
       "4959181                        1.0                        3.0      -1.0   \n",
       "4959177                        2.0                        5.0      -1.0   \n",
       "4959182                        6.0                        6.0      -1.0   \n",
       "4959178                        3.0                        4.0      -1.0   \n",
       "4959180                        7.0                       -1.0      -1.0   \n",
       "\n",
       "         star_diff  pred_grades  \n",
       "23            -1.0     1.128720  \n",
       "12            -1.0     0.893853  \n",
       "9             -1.0     0.718350  \n",
       "6             -1.0     0.596245  \n",
       "4             -1.0     0.514031  \n",
       "...            ...          ...  \n",
       "4959181       -1.0    -0.020801  \n",
       "4959177       -1.0    -0.072454  \n",
       "4959182       -1.0    -0.283133  \n",
       "4959178       -1.0    -0.334332  \n",
       "4959180       -1.0    -1.082730  \n",
       "\n",
       "[4959183 rows x 89 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the scores\n",
    "# test = X_val\n",
    "test = df_test\n",
    "test_input = test.drop(['srch_id'], axis=1)\n",
    "df_res = test\n",
    "\n",
    "\n",
    "print(\"Predicting...\")\n",
    "y_pred = best_ranker.predict(test_input)\n",
    "df_res['pred_grades'] = y_pred\n",
    "print(\"Done predicting\")\n",
    "\n",
    "df_res = df_res.sort_values(by=['srch_id', 'pred_grades'], ascending=[True, False], inplace=False)\n",
    "\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgbm_submission = df_res[['srch_id', 'prop_id']]\n",
    "lgbm_submission.to_csv(config['PATH']['SUBMISSION_DIR'] + '/lgbm_submission_optuna.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.3375755506487008, Random: 0.15050172446700524\n"
     ]
    }
   ],
   "source": [
    "# print(f\"RF: {calc_NDCG(test_ideal, pred_ideal_rf)}\\n,XGB: {calc_NDCG(test_ideal, pred_xgb_optimized)},\\nRandom: {calc_NDCG(test_ideal, pred_random)}\")\n",
    "print(f\"XGB: {calc_NDCG(df_ideal, pred_xgb)}, Random: {calc_NDCG(test_ideal, pred_random)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna + XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 13:56:31,830]\u001b[0m A new study created in memory with name: no-name-3a7cbff6-7ed5-4fc1-8c20-9778f5cce14a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 13:58:02,635]\u001b[0m Trial 0 finished with value: 0.3422170675116014 and parameters: {'n_estimators': 218, 'max_depth': 10, 'learning_rate': 0.002795642578981349, 'subsample': 0.8932459525721343, 'colsample_bytree': 0.6546014752508442, 'gamma': 0.4545479889258107, 'reg_alpha': 0.0006735472057143736, 'reg_lambda': 0.05659086785788689}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 13:58:34,110]\u001b[0m Trial 1 finished with value: 0.3296238751532763 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.00020205115375924383, 'subsample': 0.6995347755906247, 'colsample_bytree': 0.9885228465832642, 'gamma': 0.19381601429279216, 'reg_alpha': 0.03803815623242628, 'reg_lambda': 0.00015357257740569215}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 13:59:37,760]\u001b[0m Trial 2 finished with value: 0.3368665578611753 and parameters: {'n_estimators': 472, 'max_depth': 4, 'learning_rate': 0.004549507912707027, 'subsample': 0.9923851580887791, 'colsample_bytree': 0.6814279943069872, 'gamma': 0.7401357393941124, 'reg_alpha': 0.0002258603906050948, 'reg_lambda': 0.028653594053630608}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:01:29,664]\u001b[0m Trial 3 finished with value: 0.339781517888877 and parameters: {'n_estimators': 306, 'max_depth': 6, 'learning_rate': 0.060275684993274646, 'subsample': 0.620320331182772, 'colsample_bytree': 0.9464989061090534, 'gamma': 0.3525375597606377, 'reg_alpha': 0.0003216130966291681, 'reg_lambda': 0.0005114090643305632}. Best is trial 0 with value: 0.3422170675116014.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:03:28,696]\u001b[0m Trial 4 finished with value: 0.3496082715804649 and parameters: {'n_estimators': 429, 'max_depth': 5, 'learning_rate': 0.06142220536965048, 'subsample': 0.6712997719996967, 'colsample_bytree': 0.8271779419344812, 'gamma': 0.7969399896200798, 'reg_alpha': 0.000677426646577888, 'reg_lambda': 0.03700082394822008}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:05:12,196]\u001b[0m Trial 5 finished with value: 0.3384792262060793 and parameters: {'n_estimators': 255, 'max_depth': 7, 'learning_rate': 0.04445704548420475, 'subsample': 0.5764517066858506, 'colsample_bytree': 0.8572909403044449, 'gamma': 0.26447303148260715, 'reg_alpha': 0.014856269301417238, 'reg_lambda': 0.06756544690765487}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:07:47,778]\u001b[0m Trial 6 finished with value: 0.3288661873274956 and parameters: {'n_estimators': 312, 'max_depth': 10, 'learning_rate': 0.06361043068846312, 'subsample': 0.614109694485647, 'colsample_bytree': 0.690990627225202, 'gamma': 0.6320192081820498, 'reg_alpha': 0.00021742258214232484, 'reg_lambda': 0.0005896239122363013}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:08:27,834]\u001b[0m Trial 7 finished with value: 0.34384549938446224 and parameters: {'n_estimators': 69, 'max_depth': 8, 'learning_rate': 0.0010117902047042774, 'subsample': 0.5509143251305197, 'colsample_bytree': 0.8569236855819127, 'gamma': 0.971456658004933, 'reg_alpha': 0.004542345369774203, 'reg_lambda': 0.003093509800346809}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:10:40,908]\u001b[0m Trial 8 finished with value: 0.34011673137777976 and parameters: {'n_estimators': 452, 'max_depth': 7, 'learning_rate': 0.0011321008620682482, 'subsample': 0.8295478463576602, 'colsample_bytree': 0.671414737192363, 'gamma': 0.7305115721105879, 'reg_alpha': 0.00012385564006791645, 'reg_lambda': 0.0002558991665383762}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:12:07,736]\u001b[0m Trial 9 finished with value: 0.3424228910661798 and parameters: {'n_estimators': 269, 'max_depth': 8, 'learning_rate': 0.00037359210176421875, 'subsample': 0.8060751589443202, 'colsample_bytree': 0.5510785207522584, 'gamma': 0.7526724292155883, 'reg_alpha': 0.0009308042088312982, 'reg_lambda': 0.00016796739944054614}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:12:55,928]\u001b[0m Trial 10 finished with value: 0.3442294127671065 and parameters: {'n_estimators': 386, 'max_depth': 3, 'learning_rate': 0.013364142140460148, 'subsample': 0.708724261611066, 'colsample_bytree': 0.7896130232357127, 'gamma': 0.05618920251021964, 'reg_alpha': 0.0015431363571254905, 'reg_lambda': 0.014196822762253699}. Best is trial 4 with value: 0.3496082715804649.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:13:47,232]\u001b[0m Trial 11 finished with value: 0.3560830490052606 and parameters: {'n_estimators': 392, 'max_depth': 3, 'learning_rate': 0.018998420243927058, 'subsample': 0.7068269457210393, 'colsample_bytree': 0.7846266947658518, 'gamma': 0.05287718678884501, 'reg_alpha': 0.0022645116016606925, 'reg_lambda': 0.013744086612321477}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:14:39,802]\u001b[0m Trial 12 finished with value: 0.3543543071898208 and parameters: {'n_estimators': 387, 'max_depth': 3, 'learning_rate': 0.018756027574930046, 'subsample': 0.6712932319218762, 'colsample_bytree': 0.780370594379618, 'gamma': 0.5142230603254847, 'reg_alpha': 0.004081559049808262, 'reg_lambda': 0.009443211407634506}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:15:30,405]\u001b[0m Trial 13 finished with value: 0.3516628290995864 and parameters: {'n_estimators': 361, 'max_depth': 3, 'learning_rate': 0.015102319848196757, 'subsample': 0.5014584532543078, 'colsample_bytree': 0.7617930521271803, 'gamma': 0.010571810108823965, 'reg_alpha': 0.004453410464019551, 'reg_lambda': 0.009540155317686446}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:16:36,573]\u001b[0m Trial 14 finished with value: 0.3553393333527243 and parameters: {'n_estimators': 396, 'max_depth': 4, 'learning_rate': 0.01648798679985499, 'subsample': 0.7400765255992919, 'colsample_bytree': 0.7472726903550169, 'gamma': 0.47012405874481084, 'reg_alpha': 0.002494784409867919, 'reg_lambda': 0.005039066603505889}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:17:07,310]\u001b[0m Trial 15 finished with value: 0.33721518793193683 and parameters: {'n_estimators': 194, 'max_depth': 4, 'learning_rate': 0.00876749486753917, 'subsample': 0.7587969640800073, 'colsample_bytree': 0.7225094152765875, 'gamma': 0.20481708761514125, 'reg_alpha': 0.0023349612169283715, 'reg_lambda': 0.0033495501384705265}. Best is trial 11 with value: 0.3560830490052606.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:18:12,175]\u001b[0m Trial 16 finished with value: 0.3586960449767132 and parameters: {'n_estimators': 489, 'max_depth': 4, 'learning_rate': 0.027855876474626316, 'subsample': 0.7527275830005006, 'colsample_bytree': 0.6115010002948956, 'gamma': 0.1062913910208294, 'reg_alpha': 0.011119124655306968, 'reg_lambda': 0.09892315408249078}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:19:33,635]\u001b[0m Trial 17 finished with value: 0.3531469396569031 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.027832715612830964, 'subsample': 0.7777013015138864, 'colsample_bytree': 0.6041003878041254, 'gamma': 0.0997557254325905, 'reg_alpha': 0.016012295331838736, 'reg_lambda': 0.070444644128135}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:20:35,604]\u001b[0m Trial 18 finished with value: 0.35224771448175324 and parameters: {'n_estimators': 339, 'max_depth': 6, 'learning_rate': 0.027987411838695936, 'subsample': 0.861869338388761, 'colsample_bytree': 0.5065642665059094, 'gamma': 0.11492715330320435, 'reg_alpha': 0.09182530901018138, 'reg_lambda': 0.08885290572015923}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 14:21:40,752]\u001b[0m Trial 19 finished with value: 0.35291651561050097 and parameters: {'n_estimators': 430, 'max_depth': 4, 'learning_rate': 0.09529096995868931, 'subsample': 0.7375071931614383, 'colsample_bytree': 0.6244981709223065, 'gamma': 0.03240613404282796, 'reg_alpha': 0.0065337960411954756, 'reg_lambda': 0.02198876587004922}. Best is trial 16 with value: 0.3586960449767132.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [0 1 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m     42\u001b[0m xgb_model_optimized \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(objective\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmulti:softprob\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_params)\n\u001b[1;32m---> 43\u001b[0m xgb_model_optimized\u001b[39m.\u001b[39;49mfit(X_train, y_train\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m))\n\u001b[0;32m     45\u001b[0m \u001b[39m# Evaluate the optimized model\u001b[39;00m\n\u001b[0;32m     46\u001b[0m pred_xgb_optimized \u001b[39m=\u001b[39m constructs_predictions(xgb_model_optimized, X_test, ideal_df\u001b[39m=\u001b[39mtest_ideal)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Desktop\\data-mining-techniques-vu\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1440\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1435\u001b[0m     expected_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[0;32m   1436\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1437\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1438\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1439\u001b[0m ):\n\u001b[1;32m-> 1440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1442\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1443\u001b[0m     )\n\u001b[0;32m   1445\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [0 1 5]"
     ]
    }
   ],
   "source": [
    "# Optimize XGB with optuna\n",
    "import optuna\n",
    "from functools import partial\n",
    "\n",
    "def objective(trial, X_train, y_train, X_test, test_ideal):\n",
    "    y_train_xgb = y_train.astype(int)\n",
    "    y_train_xgb[y_train == 5] = 2\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-4, 1e-1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-4, 1e-1, log=True),\n",
    "    }\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(**params)\n",
    "    xgb_model.fit(X_train, y_train_xgb)\n",
    "\n",
    "    pred_xgb = constructs_predictions(xgb_model, X_test, ideal_df=test_ideal)\n",
    "    ndcg = calc_NDCG(test_ideal, pred_xgb)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "print(\"Training XGB\")\n",
    "# Assuming you have defined X_train, y_train, X_test, and test_ideal before this point.\n",
    "\n",
    "# Wrap the objective function with the input data\n",
    "objective_with_data = partial(objective, X_train=X_train, y_train=y_train, X_test=X_test, test_ideal=test_ideal)\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_with_data, n_trials=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "y_train_xgb = y_train.astype(int)\n",
    "y_train_xgb[y_train == 5] = 2\n",
    "\n",
    "best_params = study.best_params\n",
    "xgb_model_optimized = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42, **best_params)\n",
    "xgb_model_optimized.fit(X_train, y_train_xgb)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "pred_xgb_optimized = constructs_predictions(xgb_model_optimized, X_test, ideal_df=test_ideal)\n",
    "pred_xgb_submission = constructs_predictions(xgb_model_optimized, df_test)\n",
    "print(f\"XGB Optimized: {calc_NDCG(test_ideal, pred_xgb_optimized)}\")\n",
    "\n",
    "# pred_submission.to_csv(config['PATH']['DATA_DIR'] + '/submission_RF.csv', index=False)\n",
    "pred_xgb_submission.to_csv(config['PATH']['DATA_DIR'] + '/submission_XGB.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c2f59e369251f7d3cab5e49b0f40adb27d0cea1bb07f20083413ee2433d097b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
